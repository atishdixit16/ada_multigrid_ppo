{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access functions from root directory\n",
    "import sys\n",
    "sys.path.append('/data/ad181/RemoteDir/ada_multigrid_ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.ppo import PPO, MlpPolicy\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "from utils.custom_eval_callback import CustomEvalCallback, CustomEvalCallbackParallel\n",
    "from utils.env_wrappers import StateCoarse, BufferWrapper, EnvCoarseWrapper, StateCoarseMultiGrid\n",
    "from typing import Callable\n",
    "from utils.plot_functions import plot_learning\n",
    "from utils.multigrid_framework_functions import env_wrappers_multigrid, make_env, generate_beta_environement, parallalize_env, multigrid_framework\n",
    "\n",
    "from model.ressim import Grid\n",
    "from ressim_env import ResSimEnv_v0, ResSimEnv_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "case='case_2_singlegrid_one'\n",
    "data_dir='./data'\n",
    "log_dir='./data/'+case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../envs_params/env_data/env_train.pkl', 'rb') as input:\n",
    "    env_train = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define RL model and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(env_train, seed):\n",
    "    dummy_env =  generate_beta_environement(env_train, 0.5, env_train.p_x, env_train.p_y, seed)\n",
    "    dummy_env_parallel = parallalize_env(dummy_env, num_actor=64, seed=seed)\n",
    "    model = PPO(policy=MlpPolicy,\n",
    "                env=dummy_env_parallel,\n",
    "                learning_rate = 5e-4,\n",
    "                n_steps = 40,\n",
    "                batch_size = 64,\n",
    "                n_epochs = 20,\n",
    "                gamma = 0.99,\n",
    "                gae_lambda = 0.95,\n",
    "                clip_range = 0.2,\n",
    "                clip_range_vf = None,\n",
    "                ent_coef = 0.001,\n",
    "                vf_coef = 0.5,\n",
    "                max_grad_norm = 0.5,\n",
    "                use_sde= False,\n",
    "                create_eval_env= False,\n",
    "                policy_kwargs = dict(net_arch=[70,70,50], log_std_init=-1.7),\n",
    "                verbose = 1,\n",
    "                target_kl =0.1,\n",
    "                seed = seed,\n",
    "                device = \"auto\")\n",
    "    return model\n",
    "\n",
    "def generate_callback(env_train, best_model_save_path, log_path, eval_freq):\n",
    "    dummy_env = generate_beta_environement(env_train, 0.5, env_train.p_x, env_train.p_y, seed)\n",
    "    callback = CustomEvalCallbackParallel(dummy_env, \n",
    "                                          best_model_save_path=best_model_save_path, \n",
    "                                          n_eval_episodes=1,\n",
    "                                          log_path=log_path, \n",
    "                                          eval_freq=eval_freq)\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multigrid framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "seed 1: grid fidelity factor 1.0 learning ..\n",
      "environement grid size (nx x ny ): 31 x 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/ada_multigrid_ppo/utils/custom_eval_callback.py:106: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f411a051588> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f411a051320>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2560, episode_reward=0.71 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 5        |\n",
      "|    mean_reward     | 0.712    |\n",
      "| time/              |          |\n",
      "|    fps             | 132      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 2560     |\n",
      "---------------------------------\n",
      "Early stopping at step 7 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 512\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.694      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16266754 |\n",
      "|    clip_fraction        | 0.51       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.83       |\n",
      "|    explained_variance   | -0.695     |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0418    |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 0.022      |\n",
      "----------------------------------------\n",
      "Early stopping at step 16 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 1024\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.705      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15441787 |\n",
      "|    clip_fraction        | 0.56       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.83       |\n",
      "|    explained_variance   | 0.852      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0598    |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0558    |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 0.00467    |\n",
      "----------------------------------------\n",
      "Early stopping at step 17 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 1536\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.72 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.722      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 145        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15219004 |\n",
      "|    clip_fraction        | 0.594      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.88       |\n",
      "|    explained_variance   | 0.897      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.035     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0533    |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 0.0039     |\n",
      "----------------------------------------\n",
      "Early stopping at step 13 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 2048\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.72 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.719      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15362775 |\n",
      "|    clip_fraction        | 0.593      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.99       |\n",
      "|    explained_variance   | 0.92       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0693    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0528    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00335    |\n",
      "----------------------------------------\n",
      "Early stopping at step 11 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 2560\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.73 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.728      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15555656 |\n",
      "|    clip_fraction        | 0.569      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.97       |\n",
      "|    explained_variance   | 0.922      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0235    |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00335    |\n",
      "----------------------------------------\n",
      "Early stopping at step 14 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 3072\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.73 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.733      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 144        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15515184 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.94       |\n",
      "|    explained_variance   | 0.922      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0959    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.049     |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00308    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 3584\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.73 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.73       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 145        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15992875 |\n",
      "|    clip_fraction        | 0.529      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.96       |\n",
      "|    explained_variance   | 0.919      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0741    |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00326    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 4096\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.739      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15681425 |\n",
      "|    clip_fraction        | 0.556      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.01       |\n",
      "|    explained_variance   | 0.925      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0307    |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00311    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 6 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 4608\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.746     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 160       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1545586 |\n",
      "|    clip_fraction        | 0.569     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 5.99      |\n",
      "|    explained_variance   | 0.933     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0104   |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -0.0281   |\n",
      "|    std                  | 0.182     |\n",
      "|    value_loss           | 0.00279   |\n",
      "---------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 5120\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.748      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15249333 |\n",
      "|    clip_fraction        | 0.559      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6          |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0836    |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0213    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00274    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 5632\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.748      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15365057 |\n",
      "|    clip_fraction        | 0.567      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.03       |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0361    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0225    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00279    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 6144\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.749      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16798788 |\n",
      "|    clip_fraction        | 0.567      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.09       |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0277    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00277    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 6656\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.755      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16600963 |\n",
      "|    clip_fraction        | 0.547      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.14       |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0469     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00268    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 7168\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.76 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.757      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15388231 |\n",
      "|    clip_fraction        | 0.553      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.16       |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.000205   |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00273    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 7680\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.76 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.757      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15438518 |\n",
      "|    clip_fraction        | 0.566      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.18       |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0136     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0212    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00274    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 8192\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.76 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.756      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15014255 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.24       |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0128    |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0206    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00267    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 8704\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.767      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16102105 |\n",
      "|    clip_fraction        | 0.569      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.25       |\n",
      "|    explained_variance   | 0.944      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0243    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00789   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00262    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 9216\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.766      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 143        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15905306 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.22       |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0465    |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.0028     |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 9728\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.76 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.765     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1664089 |\n",
      "|    clip_fraction        | 0.599     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.21      |\n",
      "|    explained_variance   | 0.941     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.00228   |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -0.0174   |\n",
      "|    std                  | 0.18      |\n",
      "|    value_loss           | 0.00272   |\n",
      "---------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 10240\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.774      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15659472 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.25       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.12       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00728   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00259    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 10752\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.78       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15598193 |\n",
      "|    clip_fraction        | 0.558      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.24       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0148    |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00492   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00255    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 11264\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.782      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18185112 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.19       |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00426    |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0097    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00266    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 11776\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.785      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15313317 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.16       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0189    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00265    |\n",
      "----------------------------------------\n",
      "Early stopping at step 7 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 12288\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.787      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17335227 |\n",
      "|    clip_fraction        | 0.612      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.18       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00776   |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00268    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 12800\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.789      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16380718 |\n",
      "|    clip_fraction        | 0.563      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.19       |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0143    |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | 0.000898   |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00269    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 13312\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.789      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15675569 |\n",
      "|    clip_fraction        | 0.583      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.17       |\n",
      "|    explained_variance   | 0.948      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00729   |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | 0.00729    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.0026     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.793      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16815963 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.16       |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0284     |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.0025     |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 14336\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.793      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15310548 |\n",
      "|    clip_fraction        | 0.561      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.19       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.014     |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.00034   |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00246    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 14848\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.79       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15278567 |\n",
      "|    clip_fraction        | 0.55       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.2        |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0315     |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | 0.0105     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00258    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 15360\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.789      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15711813 |\n",
      "|    clip_fraction        | 0.559      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.17       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0194    |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00258    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 15872\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.792      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16669515 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.2        |\n",
      "|    explained_variance   | 0.944      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0237    |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | 0.0192     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00256    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 16384\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.796      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17403892 |\n",
      "|    clip_fraction        | 0.577      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.21       |\n",
      "|    explained_variance   | 0.948      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0262    |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | 0.00558    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00255    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 16896\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.799      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15373662 |\n",
      "|    clip_fraction        | 0.576      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.19       |\n",
      "|    explained_variance   | 0.948      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0256    |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | 0.00074    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00254    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 17408\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.8        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16574797 |\n",
      "|    clip_fraction        | 0.571      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.17       |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0787     |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | 0.0281     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00241    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 17920\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.802      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18550923 |\n",
      "|    clip_fraction        | 0.611      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.19       |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00197    |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | 0.00104    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00233    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 18432\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.801      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15338017 |\n",
      "|    clip_fraction        | 0.592      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.2        |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00111   |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | 0.000658   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00243    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 18944\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.802      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17019603 |\n",
      "|    clip_fraction        | 0.572      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.25       |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0238    |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | 0.00819    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00238    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 19456\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.805      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16716762 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.3        |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0211     |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | 0.0236     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00227    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 19968\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.808      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16939276 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.29       |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00995    |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | 0.00587    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00228    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 20480\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.809      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16764063 |\n",
      "|    clip_fraction        | 0.609      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.3        |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00799    |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | 0.0157     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00224    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 20992\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.811      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15953472 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.29       |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00293    |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | 0.0141     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00228    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 21504\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.813      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16149244 |\n",
      "|    clip_fraction        | 0.586      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.27       |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0221    |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | 0.00049    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00224    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 22016\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.815      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16109157 |\n",
      "|    clip_fraction        | 0.576      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.27       |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0552     |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | 0.0241     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00211    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 22528\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.814      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15998304 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.28       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.034      |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | 0.0208     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00208    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 23040\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.815      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15553883 |\n",
      "|    clip_fraction        | 0.579      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.3        |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0416     |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | 0.0214     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00219    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 23552\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.815      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16839546 |\n",
      "|    clip_fraction        | 0.576      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.33       |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0141     |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | 0.0141     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00212    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 24064\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.817      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19668165 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.34       |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0222    |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | 0.0256     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00204    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 24576\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.817      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15275018 |\n",
      "|    clip_fraction        | 0.623      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.36       |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0361     |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | 0.00134    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.00188    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 25088\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.817      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15924972 |\n",
      "|    clip_fraction        | 0.583      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.43       |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00634   |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | 0.0161     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.0018     |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 25600\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.818      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17828777 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.49       |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.056      |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | 0.0141     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.0018     |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 26112\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.817      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15655991 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.56       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0288     |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | 0.0118     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00175    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 26624\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.816      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18795809 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.59       |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0793     |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | 0.00735    |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00179    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 27136\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.819      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16047081 |\n",
      "|    clip_fraction        | 0.592      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.53       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0567     |\n",
      "|    n_updates            | 1060       |\n",
      "|    policy_gradient_loss | 0.0154     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.0018     |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 27648\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.82       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15902509 |\n",
      "|    clip_fraction        | 0.593      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.51       |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0375    |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | 0.025      |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.0018     |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 28160\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.822      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15824345 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.55       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0579     |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | 0.0216     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00164    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 28672\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.823      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15369502 |\n",
      "|    clip_fraction        | 0.578      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.62       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0101     |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | 0.0186     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00173    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 29184\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.823      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15995161 |\n",
      "|    clip_fraction        | 0.622      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.63       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0652     |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | 0.00443    |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00169    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 29696\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.825      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16658254 |\n",
      "|    clip_fraction        | 0.612      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.61       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0484    |\n",
      "|    n_updates            | 1160       |\n",
      "|    policy_gradient_loss | 0.0198     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00175    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 30208\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.826     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1535939 |\n",
      "|    clip_fraction        | 0.586     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.62      |\n",
      "|    explained_variance   | 0.97      |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.033    |\n",
      "|    n_updates            | 1180      |\n",
      "|    policy_gradient_loss | 0.0262    |\n",
      "|    std                  | 0.177     |\n",
      "|    value_loss           | 0.00174   |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 30720\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.827      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16184987 |\n",
      "|    clip_fraction        | 0.582      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.66       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0516     |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | 0.0245     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00175    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 31232\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.829      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15289529 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.68       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0421     |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | 0.0159     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00177    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 31744\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.827      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15109316 |\n",
      "|    clip_fraction        | 0.566      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.67       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0136     |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | 0.0383     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00191    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 32256\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.828      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17725965 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.69       |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0632     |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | 0.0298     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00186    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 32768\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 5        |\n",
      "|    mean_reward          | 0.827    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 151      |\n",
      "|    iterations           | 1        |\n",
      "|    time_elapsed         | 16       |\n",
      "|    total_timesteps      | 2560     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.179606 |\n",
      "|    clip_fraction        | 0.601    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 6.64     |\n",
      "|    explained_variance   | 0.97     |\n",
      "|    learning_rate        | 0.0005   |\n",
      "|    loss                 | 0.0119   |\n",
      "|    n_updates            | 1280     |\n",
      "|    policy_gradient_loss | 0.0251   |\n",
      "|    std                  | 0.177    |\n",
      "|    value_loss           | 0.0017   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 33280\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.828      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15517561 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.61       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00277    |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | 0.0218     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00173    |\n",
      "----------------------------------------\n",
      "Early stopping at step 9 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 33792\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.829      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15268932 |\n",
      "|    clip_fraction        | 0.647      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.64       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0267    |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | 0.00208    |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00182    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 34304\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18199946 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.66       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0229    |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | 0.0221     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00181    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 34816\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.828      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15478061 |\n",
      "|    clip_fraction        | 0.611      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.71       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0325     |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | 0.0211     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.002      |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 35328\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.827      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16567144 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.72       |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0139     |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | 0.029      |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00196    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 35840\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16206777 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.72       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0211     |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | 0.0365     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00184    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 36352\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.831      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15157667 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.72       |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00853    |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | 0.0218     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00182    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 36864\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.833     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1634456 |\n",
      "|    clip_fraction        | 0.608     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.7       |\n",
      "|    explained_variance   | 0.973     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0947    |\n",
      "|    n_updates            | 1440      |\n",
      "|    policy_gradient_loss | 0.0209    |\n",
      "|    std                  | 0.177     |\n",
      "|    value_loss           | 0.00175   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 37376\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.834      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15755494 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.68       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.141      |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | 0.0382     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00192    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 37888\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.836      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16573623 |\n",
      "|    clip_fraction        | 0.593      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.71       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0388    |\n",
      "|    n_updates            | 1480       |\n",
      "|    policy_gradient_loss | 0.0271     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00179    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 38400\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.837     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1704388 |\n",
      "|    clip_fraction        | 0.589     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.76      |\n",
      "|    explained_variance   | 0.969     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0718    |\n",
      "|    n_updates            | 1500      |\n",
      "|    policy_gradient_loss | 0.0482    |\n",
      "|    std                  | 0.176     |\n",
      "|    value_loss           | 0.00189   |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 38912\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.838      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16443205 |\n",
      "|    clip_fraction        | 0.589      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.76       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.014      |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | 0.035      |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00168    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 39424\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.837      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17242858 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.77       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.197      |\n",
      "|    n_updates            | 1540       |\n",
      "|    policy_gradient_loss | 0.0306     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00187    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 39936\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.839      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18063404 |\n",
      "|    clip_fraction        | 0.62       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.82       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0332     |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | 0.032      |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00178    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 40448\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.84       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15302345 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.86       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0126    |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | 0.0275     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.0019     |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 40960\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.84      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1701391 |\n",
      "|    clip_fraction        | 0.59      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.89      |\n",
      "|    explained_variance   | 0.971     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.152     |\n",
      "|    n_updates            | 1600      |\n",
      "|    policy_gradient_loss | 0.0541    |\n",
      "|    std                  | 0.175     |\n",
      "|    value_loss           | 0.00193   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 41472\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.84       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15183409 |\n",
      "|    clip_fraction        | 0.609      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.91       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0699     |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | 0.0342     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00173    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 41984\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.84       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15054266 |\n",
      "|    clip_fraction        | 0.546      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.91       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.019      |\n",
      "|    n_updates            | 1640       |\n",
      "|    policy_gradient_loss | 0.0381     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00183    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 42496\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.842      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17639801 |\n",
      "|    clip_fraction        | 0.643      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.96       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0098     |\n",
      "|    n_updates            | 1660       |\n",
      "|    policy_gradient_loss | 0.026      |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00176    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 43008\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.842      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18686184 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7          |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0114     |\n",
      "|    n_updates            | 1680       |\n",
      "|    policy_gradient_loss | 0.0444     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00172    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 43520\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.843      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15709192 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.99       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0411     |\n",
      "|    n_updates            | 1700       |\n",
      "|    policy_gradient_loss | 0.0447     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00162    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 44032\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.844      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17086485 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.01       |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00137    |\n",
      "|    n_updates            | 1720       |\n",
      "|    policy_gradient_loss | 0.05       |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.0017     |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 44544\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.846      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16066426 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.05       |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0767     |\n",
      "|    n_updates            | 1740       |\n",
      "|    policy_gradient_loss | 0.0398     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00177    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 45056\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.847      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16233155 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.05       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0323    |\n",
      "|    n_updates            | 1760       |\n",
      "|    policy_gradient_loss | 0.0253     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.0017     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 45568\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.847      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18273625 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.05       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0202    |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | 0.0301     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00177    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 46080\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.847      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18879631 |\n",
      "|    clip_fraction        | 0.6        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.05       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0598     |\n",
      "|    n_updates            | 1800       |\n",
      "|    policy_gradient_loss | 0.066      |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00195    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 46592\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.846      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15576747 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.06       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.017     |\n",
      "|    n_updates            | 1820       |\n",
      "|    policy_gradient_loss | 0.0432     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00168    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 47104\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.845      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15764269 |\n",
      "|    clip_fraction        | 0.571      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.06       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.146      |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | 0.0495     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00179    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 47616\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.846      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21646914 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.07       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0617     |\n",
      "|    n_updates            | 1860       |\n",
      "|    policy_gradient_loss | 0.0487     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00179    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 48128\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.847      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17344259 |\n",
      "|    clip_fraction        | 0.6        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.11       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0368     |\n",
      "|    n_updates            | 1880       |\n",
      "|    policy_gradient_loss | 0.0575     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00182    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 48640\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.847      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17166133 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.13       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.199      |\n",
      "|    n_updates            | 1900       |\n",
      "|    policy_gradient_loss | 0.0433     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00176    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 49152\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.847      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15482223 |\n",
      "|    clip_fraction        | 0.602      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.13       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 1920       |\n",
      "|    policy_gradient_loss | 0.0523     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00187    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 49664\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.848     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 147       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2010636 |\n",
      "|    clip_fraction        | 0.618     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.12      |\n",
      "|    explained_variance   | 0.972     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0852    |\n",
      "|    n_updates            | 1940      |\n",
      "|    policy_gradient_loss | 0.0418    |\n",
      "|    std                  | 0.174     |\n",
      "|    value_loss           | 0.00179   |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 50176\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.848      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16591987 |\n",
      "|    clip_fraction        | 0.584      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.1        |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0518     |\n",
      "|    n_updates            | 1960       |\n",
      "|    policy_gradient_loss | 0.0339     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00174    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 50688\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19476128 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.1        |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | 0.0578     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.0018     |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 51200\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15997481 |\n",
      "|    clip_fraction        | 0.575      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.09       |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0286     |\n",
      "|    n_updates            | 2000       |\n",
      "|    policy_gradient_loss | 0.046      |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00162    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 51712\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20284991 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.04       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.129      |\n",
      "|    n_updates            | 2040       |\n",
      "|    policy_gradient_loss | 0.0665     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00168    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 52736\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17469065 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.03       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 2060       |\n",
      "|    policy_gradient_loss | 0.0616     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00166    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 53248\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16857168 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.04       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0487     |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | 0.029      |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00142    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 53760\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.852     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 159       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1661666 |\n",
      "|    clip_fraction        | 0.563     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.06      |\n",
      "|    explained_variance   | 0.978     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.00541  |\n",
      "|    n_updates            | 2100      |\n",
      "|    policy_gradient_loss | 0.0461    |\n",
      "|    std                  | 0.174     |\n",
      "|    value_loss           | 0.00148   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 54272\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15470675 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.09       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0246     |\n",
      "|    n_updates            | 2120       |\n",
      "|    policy_gradient_loss | 0.053      |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00153    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 54784\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17282172 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.07       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.155      |\n",
      "|    n_updates            | 2140       |\n",
      "|    policy_gradient_loss | 0.0555     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00144    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 55296\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18603465 |\n",
      "|    clip_fraction        | 0.598      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.07       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00916    |\n",
      "|    n_updates            | 2160       |\n",
      "|    policy_gradient_loss | 0.0488     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00153    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 55808\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20542856 |\n",
      "|    clip_fraction        | 0.592      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.05       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0739     |\n",
      "|    n_updates            | 2180       |\n",
      "|    policy_gradient_loss | 0.0413     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00174    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 56320\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16193172 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.07       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0448     |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | 0.0317     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00138    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 56832\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17430185 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.08       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.057      |\n",
      "|    n_updates            | 2220       |\n",
      "|    policy_gradient_loss | 0.046      |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00156    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 57344\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16992244 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.1        |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0442     |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | 0.0423     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00157    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 57856\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.85      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1977537 |\n",
      "|    clip_fraction        | 0.593     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.14      |\n",
      "|    explained_variance   | 0.976     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0981    |\n",
      "|    n_updates            | 2260      |\n",
      "|    policy_gradient_loss | 0.0664    |\n",
      "|    std                  | 0.174     |\n",
      "|    value_loss           | 0.00165   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 58368\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15680878 |\n",
      "|    clip_fraction        | 0.595      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.14       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0794     |\n",
      "|    n_updates            | 2280       |\n",
      "|    policy_gradient_loss | 0.0529     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00161    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 58880\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15291125 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.14       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0767     |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | 0.0414     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00164    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 59392\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19916238 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.12       |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.168      |\n",
      "|    n_updates            | 2320       |\n",
      "|    policy_gradient_loss | 0.061      |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00164    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 59904\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15766278 |\n",
      "|    clip_fraction        | 0.584      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.11       |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0165     |\n",
      "|    n_updates            | 2340       |\n",
      "|    policy_gradient_loss | 0.0515     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00163    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 60416\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.85      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2176086 |\n",
      "|    clip_fraction        | 0.631     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.12      |\n",
      "|    explained_variance   | 0.975     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.137     |\n",
      "|    n_updates            | 2360      |\n",
      "|    policy_gradient_loss | 0.0622    |\n",
      "|    std                  | 0.174     |\n",
      "|    value_loss           | 0.00161   |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 60928\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15129183 |\n",
      "|    clip_fraction        | 0.579      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.09       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0302     |\n",
      "|    n_updates            | 2380       |\n",
      "|    policy_gradient_loss | 0.0349     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00149    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 61440\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.851     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1844999 |\n",
      "|    clip_fraction        | 0.585     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.06      |\n",
      "|    explained_variance   | 0.976     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0831    |\n",
      "|    n_updates            | 2400      |\n",
      "|    policy_gradient_loss | 0.0354    |\n",
      "|    std                  | 0.175     |\n",
      "|    value_loss           | 0.00155   |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 61952\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18528321 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.02       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0669     |\n",
      "|    n_updates            | 2420       |\n",
      "|    policy_gradient_loss | 0.047      |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00157    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 62464\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17106171 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.01       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0626     |\n",
      "|    n_updates            | 2440       |\n",
      "|    policy_gradient_loss | 0.0512     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00139    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 62976\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15287344 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.01       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0528     |\n",
      "|    n_updates            | 2460       |\n",
      "|    policy_gradient_loss | 0.0524     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00137    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 63488\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.849      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15468414 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7          |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 2480       |\n",
      "|    policy_gradient_loss | 0.0301     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00123    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 64000\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15779558 |\n",
      "|    clip_fraction        | 0.578      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.02       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0208    |\n",
      "|    n_updates            | 2500       |\n",
      "|    policy_gradient_loss | 0.0498     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00128    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 64512\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.849     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1533711 |\n",
      "|    clip_fraction        | 0.56      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.04      |\n",
      "|    explained_variance   | 0.981     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0563    |\n",
      "|    n_updates            | 2520      |\n",
      "|    policy_gradient_loss | 0.0424    |\n",
      "|    std                  | 0.175     |\n",
      "|    value_loss           | 0.00135   |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 65024\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.849      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17193942 |\n",
      "|    clip_fraction        | 0.573      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.04       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0545     |\n",
      "|    n_updates            | 2540       |\n",
      "|    policy_gradient_loss | 0.0463     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00141    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 65536\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 5        |\n",
      "|    mean_reward          | 0.849    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 154      |\n",
      "|    iterations           | 1        |\n",
      "|    time_elapsed         | 16       |\n",
      "|    total_timesteps      | 2560     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.175837 |\n",
      "|    clip_fraction        | 0.589    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 7.03     |\n",
      "|    explained_variance   | 0.981    |\n",
      "|    learning_rate        | 0.0005   |\n",
      "|    loss                 | 0.0844   |\n",
      "|    n_updates            | 2560     |\n",
      "|    policy_gradient_loss | 0.0582   |\n",
      "|    std                  | 0.175    |\n",
      "|    value_loss           | 0.00144  |\n",
      "--------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 66048\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.849     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2104789 |\n",
      "|    clip_fraction        | 0.589     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.01      |\n",
      "|    explained_variance   | 0.98      |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0682    |\n",
      "|    n_updates            | 2580      |\n",
      "|    policy_gradient_loss | 0.0522    |\n",
      "|    std                  | 0.175     |\n",
      "|    value_loss           | 0.00128   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 66560\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.849      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15057087 |\n",
      "|    clip_fraction        | 0.589      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.99       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0637     |\n",
      "|    n_updates            | 2600       |\n",
      "|    policy_gradient_loss | 0.0423     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00121    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 67072\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.849     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1655508 |\n",
      "|    clip_fraction        | 0.577     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.99      |\n",
      "|    explained_variance   | 0.98      |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0115    |\n",
      "|    n_updates            | 2620      |\n",
      "|    policy_gradient_loss | 0.0577    |\n",
      "|    std                  | 0.175     |\n",
      "|    value_loss           | 0.00136   |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 67584\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.849      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15133993 |\n",
      "|    clip_fraction        | 0.559      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.96       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0774     |\n",
      "|    n_updates            | 2640       |\n",
      "|    policy_gradient_loss | 0.0506     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00148    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 68096\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.849      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17444621 |\n",
      "|    clip_fraction        | 0.559      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.93       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0791     |\n",
      "|    n_updates            | 2660       |\n",
      "|    policy_gradient_loss | 0.0588     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00141    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 68608\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.849      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16494432 |\n",
      "|    clip_fraction        | 0.586      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.91       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0871     |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | 0.0505     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00132    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 69120\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.849      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15829301 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.93       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00916    |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | 0.0453     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00133    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 69632\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.849     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1928297 |\n",
      "|    clip_fraction        | 0.625     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.95      |\n",
      "|    explained_variance   | 0.979     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0668    |\n",
      "|    n_updates            | 2720      |\n",
      "|    policy_gradient_loss | 0.0375    |\n",
      "|    std                  | 0.176     |\n",
      "|    value_loss           | 0.00136   |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 70144\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.85      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1531076 |\n",
      "|    clip_fraction        | 0.618     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.93      |\n",
      "|    explained_variance   | 0.98      |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0227    |\n",
      "|    n_updates            | 2740      |\n",
      "|    policy_gradient_loss | 0.0396    |\n",
      "|    std                  | 0.176     |\n",
      "|    value_loss           | 0.00142   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 70656\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15329893 |\n",
      "|    clip_fraction        | 0.593      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.96       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.134      |\n",
      "|    n_updates            | 2760       |\n",
      "|    policy_gradient_loss | 0.0468     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00132    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 71168\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15845561 |\n",
      "|    clip_fraction        | 0.625      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.96       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0501     |\n",
      "|    n_updates            | 2780       |\n",
      "|    policy_gradient_loss | 0.0272     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00127    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 71680\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15740569 |\n",
      "|    clip_fraction        | 0.595      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.96       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.215      |\n",
      "|    n_updates            | 2800       |\n",
      "|    policy_gradient_loss | 0.0408     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00124    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 72192\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22039695 |\n",
      "|    clip_fraction        | 0.586      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.96       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.32       |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | 0.0638     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00137    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 72704\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17570779 |\n",
      "|    clip_fraction        | 0.615      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.93       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0915     |\n",
      "|    n_updates            | 2840       |\n",
      "|    policy_gradient_loss | 0.0436     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00134    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 73216\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 5        |\n",
      "|    mean_reward          | 0.852    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 152      |\n",
      "|    iterations           | 1        |\n",
      "|    time_elapsed         | 16       |\n",
      "|    total_timesteps      | 2560     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.156881 |\n",
      "|    clip_fraction        | 0.586    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 6.9      |\n",
      "|    explained_variance   | 0.981    |\n",
      "|    learning_rate        | 0.0005   |\n",
      "|    loss                 | 0.0199   |\n",
      "|    n_updates            | 2860     |\n",
      "|    policy_gradient_loss | 0.0418   |\n",
      "|    std                  | 0.176    |\n",
      "|    value_loss           | 0.00134  |\n",
      "--------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 73728\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15655227 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.91       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0291     |\n",
      "|    n_updates            | 2880       |\n",
      "|    policy_gradient_loss | 0.0495     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00125    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 74240\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17587185 |\n",
      "|    clip_fraction        | 0.625      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.92       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0125     |\n",
      "|    n_updates            | 2900       |\n",
      "|    policy_gradient_loss | 0.0554     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00132    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 74752\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18418786 |\n",
      "|    clip_fraction        | 0.609      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.9        |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0267     |\n",
      "|    n_updates            | 2920       |\n",
      "|    policy_gradient_loss | 0.0343     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00124    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 75264\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.852     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2006638 |\n",
      "|    clip_fraction        | 0.606     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.87      |\n",
      "|    explained_variance   | 0.982     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0748    |\n",
      "|    n_updates            | 2940      |\n",
      "|    policy_gradient_loss | 0.0351    |\n",
      "|    std                  | 0.176     |\n",
      "|    value_loss           | 0.00125   |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 75776\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19062927 |\n",
      "|    clip_fraction        | 0.62       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.85       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0235     |\n",
      "|    n_updates            | 2960       |\n",
      "|    policy_gradient_loss | 0.0612     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00131    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 76288\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16804527 |\n",
      "|    clip_fraction        | 0.584      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.88       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0686     |\n",
      "|    n_updates            | 2980       |\n",
      "|    policy_gradient_loss | 0.0509     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00141    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 76800\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.852     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1526309 |\n",
      "|    clip_fraction        | 0.636     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.84      |\n",
      "|    explained_variance   | 0.98      |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0759    |\n",
      "|    n_updates            | 3000      |\n",
      "|    policy_gradient_loss | 0.028     |\n",
      "|    std                  | 0.177     |\n",
      "|    value_loss           | 0.00132   |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 77312\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15721007 |\n",
      "|    clip_fraction        | 0.56       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.81       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0145     |\n",
      "|    n_updates            | 3020       |\n",
      "|    policy_gradient_loss | 0.0472     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.0013     |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 77824\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16076444 |\n",
      "|    clip_fraction        | 0.582      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.82       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0583     |\n",
      "|    n_updates            | 3040       |\n",
      "|    policy_gradient_loss | 0.032      |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00122    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 78336\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16431198 |\n",
      "|    clip_fraction        | 0.573      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.86       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00914   |\n",
      "|    n_updates            | 3060       |\n",
      "|    policy_gradient_loss | 0.0547     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00132    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 78848\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19267634 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.83       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0216     |\n",
      "|    n_updates            | 3080       |\n",
      "|    policy_gradient_loss | 0.0366     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00119    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 79360\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17329973 |\n",
      "|    clip_fraction        | 0.586      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.8        |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.049      |\n",
      "|    n_updates            | 3100       |\n",
      "|    policy_gradient_loss | 0.056      |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 79872\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16371617 |\n",
      "|    clip_fraction        | 0.6        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.85       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0544     |\n",
      "|    n_updates            | 3120       |\n",
      "|    policy_gradient_loss | 0.0388     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00131    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 80384\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17232096 |\n",
      "|    clip_fraction        | 0.6        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.89       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0676     |\n",
      "|    n_updates            | 3140       |\n",
      "|    policy_gradient_loss | 0.0392     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00129    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 80896\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19685659 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.89       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.155      |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | 0.0519     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00116    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 81408\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21340194 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.92       |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0613     |\n",
      "|    n_updates            | 3180       |\n",
      "|    policy_gradient_loss | 0.0459     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 81920\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16918445 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.93       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0852     |\n",
      "|    n_updates            | 3200       |\n",
      "|    policy_gradient_loss | 0.0504     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00131    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 82432\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15141164 |\n",
      "|    clip_fraction        | 0.622      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.92       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.000233   |\n",
      "|    n_updates            | 3220       |\n",
      "|    policy_gradient_loss | 0.034      |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00118    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 82944\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19696197 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.9        |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0514     |\n",
      "|    n_updates            | 3240       |\n",
      "|    policy_gradient_loss | 0.0486     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 83456\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.851      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15047982 |\n",
      "|    clip_fraction        | 0.595      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.88       |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.191      |\n",
      "|    n_updates            | 3260       |\n",
      "|    policy_gradient_loss | 0.048      |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00108    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 83968\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16469237 |\n",
      "|    clip_fraction        | 0.583      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.86       |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00437    |\n",
      "|    n_updates            | 3280       |\n",
      "|    policy_gradient_loss | 0.0503     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00112    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 84480\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17982507 |\n",
      "|    clip_fraction        | 0.627      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.83       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0724     |\n",
      "|    n_updates            | 3300       |\n",
      "|    policy_gradient_loss | 0.035      |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00116    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 84992\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.852     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1546489 |\n",
      "|    clip_fraction        | 0.593     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.83      |\n",
      "|    explained_variance   | 0.983     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.089     |\n",
      "|    n_updates            | 3320      |\n",
      "|    policy_gradient_loss | 0.0576    |\n",
      "|    std                  | 0.177     |\n",
      "|    value_loss           | 0.0012    |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 85504\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15157734 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.81       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00246    |\n",
      "|    n_updates            | 3340       |\n",
      "|    policy_gradient_loss | 0.0419     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.000983   |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 86016\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16321732 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.8        |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0412     |\n",
      "|    n_updates            | 3360       |\n",
      "|    policy_gradient_loss | 0.0278     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.000992   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 86528\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15434107 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.79       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0335     |\n",
      "|    n_updates            | 3380       |\n",
      "|    policy_gradient_loss | 0.0362     |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00104    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 87040\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17069212 |\n",
      "|    clip_fraction        | 0.626      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.74       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0555     |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | 0.0306     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000956   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 87552\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15016302 |\n",
      "|    clip_fraction        | 0.62       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.69       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.000413  |\n",
      "|    n_updates            | 3420       |\n",
      "|    policy_gradient_loss | 0.0382     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00105    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 88064\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15767053 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.67       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0362     |\n",
      "|    n_updates            | 3440       |\n",
      "|    policy_gradient_loss | 0.0347     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000965   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 88576\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16771416 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.68       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0452     |\n",
      "|    n_updates            | 3460       |\n",
      "|    policy_gradient_loss | 0.0194     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00105    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 89088\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19483641 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.64       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0466     |\n",
      "|    n_updates            | 3480       |\n",
      "|    policy_gradient_loss | 0.0338     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000924   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 89600\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17370424 |\n",
      "|    clip_fraction        | 0.609      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.64       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00197   |\n",
      "|    n_updates            | 3500       |\n",
      "|    policy_gradient_loss | 0.0395     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000915   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 90112\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15261224 |\n",
      "|    clip_fraction        | 0.594      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.65       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0406     |\n",
      "|    n_updates            | 3520       |\n",
      "|    policy_gradient_loss | 0.0475     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000953   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 90624\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15430667 |\n",
      "|    clip_fraction        | 0.584      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.65       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0426     |\n",
      "|    n_updates            | 3540       |\n",
      "|    policy_gradient_loss | 0.0528     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000906   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 91136\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15592198 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.67       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00214   |\n",
      "|    n_updates            | 3560       |\n",
      "|    policy_gradient_loss | 0.0307     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000969   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 91648\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16609064 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.68       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0543     |\n",
      "|    n_updates            | 3600       |\n",
      "|    policy_gradient_loss | 0.0348     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000904   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 92672\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19626965 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.7        |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0554     |\n",
      "|    n_updates            | 3620       |\n",
      "|    policy_gradient_loss | 0.0426     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000966   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 93184\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16490608 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.69       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0909     |\n",
      "|    n_updates            | 3640       |\n",
      "|    policy_gradient_loss | 0.0548     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 93696\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17995381 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.68       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.109      |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | 0.0594     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00106    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 94208\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.855     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 155       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1809984 |\n",
      "|    clip_fraction        | 0.61      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.69      |\n",
      "|    explained_variance   | 0.986     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0569    |\n",
      "|    n_updates            | 3680      |\n",
      "|    policy_gradient_loss | 0.0404    |\n",
      "|    std                  | 0.178     |\n",
      "|    value_loss           | 0.00097   |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 94720\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15072529 |\n",
      "|    clip_fraction        | 0.629      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.71       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0442     |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | 0.036      |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000978   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 95232\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.855     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1922822 |\n",
      "|    clip_fraction        | 0.637     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.68      |\n",
      "|    explained_variance   | 0.986     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0234   |\n",
      "|    n_updates            | 3720      |\n",
      "|    policy_gradient_loss | 0.0538    |\n",
      "|    std                  | 0.178     |\n",
      "|    value_loss           | 0.000912  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 95744\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19934411 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.66       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0752     |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | 0.059      |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000894   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 96256\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18662205 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.65       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.065      |\n",
      "|    n_updates            | 3760       |\n",
      "|    policy_gradient_loss | 0.0464     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.000931   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 96768\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.855     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1705114 |\n",
      "|    clip_fraction        | 0.639     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.62      |\n",
      "|    explained_variance   | 0.986     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.114     |\n",
      "|    n_updates            | 3780      |\n",
      "|    policy_gradient_loss | 0.0367    |\n",
      "|    std                  | 0.179     |\n",
      "|    value_loss           | 0.000949  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 97280\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19918248 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.6        |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.014      |\n",
      "|    n_updates            | 3800       |\n",
      "|    policy_gradient_loss | 0.0392     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000957   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 97792\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16181853 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.58       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0969     |\n",
      "|    n_updates            | 3820       |\n",
      "|    policy_gradient_loss | 0.0458     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000915   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 98304\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16271842 |\n",
      "|    clip_fraction        | 0.583      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.57       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.12       |\n",
      "|    n_updates            | 3840       |\n",
      "|    policy_gradient_loss | 0.0506     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000922   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 98816\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16068855 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.61       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0246     |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | 0.0387     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00092    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 99328\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16297425 |\n",
      "|    clip_fraction        | 0.582      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.61       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0303    |\n",
      "|    n_updates            | 3880       |\n",
      "|    policy_gradient_loss | 0.041      |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000898   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 99840\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15410616 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.57       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0563     |\n",
      "|    n_updates            | 3900       |\n",
      "|    policy_gradient_loss | 0.0289     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000902   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 100352\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16337457 |\n",
      "|    clip_fraction        | 0.646      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.52       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00585    |\n",
      "|    n_updates            | 3920       |\n",
      "|    policy_gradient_loss | 0.0305     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000906   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 100864\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17415006 |\n",
      "|    clip_fraction        | 0.612      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.49       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0145    |\n",
      "|    n_updates            | 3940       |\n",
      "|    policy_gradient_loss | 0.0366     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000952   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 101376\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18102854 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.49       |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.077      |\n",
      "|    n_updates            | 3960       |\n",
      "|    policy_gradient_loss | 0.0532     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00108    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 101888\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16395597 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.51       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0122     |\n",
      "|    n_updates            | 3980       |\n",
      "|    policy_gradient_loss | 0.0471     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000953   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 102400\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15865341 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.51       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.121      |\n",
      "|    n_updates            | 4000       |\n",
      "|    policy_gradient_loss | 0.03       |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000855   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 102912\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15578319 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.49       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0324     |\n",
      "|    n_updates            | 4020       |\n",
      "|    policy_gradient_loss | 0.0437     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000887   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 103424\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17607145 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.51       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0179     |\n",
      "|    n_updates            | 4040       |\n",
      "|    policy_gradient_loss | 0.0359     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000909   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 103936\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.855     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2034039 |\n",
      "|    clip_fraction        | 0.613     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.52      |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0433    |\n",
      "|    n_updates            | 4060      |\n",
      "|    policy_gradient_loss | 0.0433    |\n",
      "|    std                  | 0.179     |\n",
      "|    value_loss           | 0.000861  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 104448\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15725946 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.54       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0541     |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | 0.0375     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.000919   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 104960\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15940589 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.53       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0181     |\n",
      "|    n_updates            | 4100       |\n",
      "|    policy_gradient_loss | 0.0389     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000903   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 105472\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16680345 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.51       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.054      |\n",
      "|    n_updates            | 4120       |\n",
      "|    policy_gradient_loss | 0.048      |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000912   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 105984\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17780867 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.51       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.124      |\n",
      "|    n_updates            | 4140       |\n",
      "|    policy_gradient_loss | 0.0451     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000868   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 106496\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.855     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1979627 |\n",
      "|    clip_fraction        | 0.605     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.5       |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0467    |\n",
      "|    n_updates            | 4160      |\n",
      "|    policy_gradient_loss | 0.0539    |\n",
      "|    std                  | 0.18      |\n",
      "|    value_loss           | 0.000848  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 107008\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20066004 |\n",
      "|    clip_fraction        | 0.634      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.46       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.106      |\n",
      "|    n_updates            | 4180       |\n",
      "|    policy_gradient_loss | 0.0574     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000874   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 107520\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16045743 |\n",
      "|    clip_fraction        | 0.61       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.43       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0613     |\n",
      "|    n_updates            | 4200       |\n",
      "|    policy_gradient_loss | 0.0365     |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.000799   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 108032\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16416538 |\n",
      "|    clip_fraction        | 0.637      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.43       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.068      |\n",
      "|    n_updates            | 4220       |\n",
      "|    policy_gradient_loss | 0.0492     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00081    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 108544\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15681723 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.41       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0298     |\n",
      "|    n_updates            | 4240       |\n",
      "|    policy_gradient_loss | 0.0444     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.000897   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 109056\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16423476 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.39       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0468     |\n",
      "|    n_updates            | 4260       |\n",
      "|    policy_gradient_loss | 0.0639     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.000944   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 109568\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15181455 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.36       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0162    |\n",
      "|    n_updates            | 4280       |\n",
      "|    policy_gradient_loss | 0.0636     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.000872   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 110080\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.855     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1616029 |\n",
      "|    clip_fraction        | 0.606     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.35      |\n",
      "|    explained_variance   | 0.986     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0642    |\n",
      "|    n_updates            | 4300      |\n",
      "|    policy_gradient_loss | 0.0513    |\n",
      "|    std                  | 0.181     |\n",
      "|    value_loss           | 0.000902  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 110592\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.855     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1640733 |\n",
      "|    clip_fraction        | 0.613     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.37      |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0914    |\n",
      "|    n_updates            | 4320      |\n",
      "|    policy_gradient_loss | 0.0432    |\n",
      "|    std                  | 0.181     |\n",
      "|    value_loss           | 0.000934  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 111104\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20990908 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.37       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0576     |\n",
      "|    n_updates            | 4340       |\n",
      "|    policy_gradient_loss | 0.0385     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.000879   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 111616\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18943453 |\n",
      "|    clip_fraction        | 0.618      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.33       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00633    |\n",
      "|    n_updates            | 4360       |\n",
      "|    policy_gradient_loss | 0.0546     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.000799   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 112128\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16289917 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.3        |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0619     |\n",
      "|    n_updates            | 4380       |\n",
      "|    policy_gradient_loss | 0.0451     |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00079    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 112640\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15818305 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.31       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 4400       |\n",
      "|    policy_gradient_loss | 0.0575     |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.000752   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 113152\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17005086 |\n",
      "|    clip_fraction        | 0.586      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.3        |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0909     |\n",
      "|    n_updates            | 4420       |\n",
      "|    policy_gradient_loss | 0.0516     |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.000828   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 113664\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.856     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1727787 |\n",
      "|    clip_fraction        | 0.598     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.28      |\n",
      "|    explained_variance   | 0.988     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0594    |\n",
      "|    n_updates            | 4440      |\n",
      "|    policy_gradient_loss | 0.0352    |\n",
      "|    std                  | 0.182     |\n",
      "|    value_loss           | 0.000847  |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 114176\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.855     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 148       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1632802 |\n",
      "|    clip_fraction        | 0.614     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.3       |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0907    |\n",
      "|    n_updates            | 4460      |\n",
      "|    policy_gradient_loss | 0.0571    |\n",
      "|    std                  | 0.182     |\n",
      "|    value_loss           | 0.000856  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 114688\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16798255 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.28       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.061      |\n",
      "|    n_updates            | 4480       |\n",
      "|    policy_gradient_loss | 0.0466     |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00085    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 115200\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17949718 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.27       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0691     |\n",
      "|    n_updates            | 4500       |\n",
      "|    policy_gradient_loss | 0.0562     |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.000945   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 115712\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19038968 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.27       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.118      |\n",
      "|    n_updates            | 4520       |\n",
      "|    policy_gradient_loss | 0.0507     |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.000902   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 116224\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16687155 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.23       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.103      |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | 0.0512     |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 0.000953   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 116736\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16641079 |\n",
      "|    clip_fraction        | 0.62       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.19       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0993     |\n",
      "|    n_updates            | 4560       |\n",
      "|    policy_gradient_loss | 0.0324     |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 0.00082    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 117248\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21258292 |\n",
      "|    clip_fraction        | 0.594      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.18       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0517     |\n",
      "|    n_updates            | 4580       |\n",
      "|    policy_gradient_loss | 0.0425     |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 0.00082    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 117760\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16018963 |\n",
      "|    clip_fraction        | 0.609      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.16       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.135      |\n",
      "|    n_updates            | 4600       |\n",
      "|    policy_gradient_loss | 0.0403     |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 0.000789   |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 118272\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20804396 |\n",
      "|    clip_fraction        | 0.629      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.13       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.05       |\n",
      "|    n_updates            | 4620       |\n",
      "|    policy_gradient_loss | 0.028      |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 0.000902   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 118784\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16576186 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.11       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0428     |\n",
      "|    n_updates            | 4640       |\n",
      "|    policy_gradient_loss | 0.0273     |\n",
      "|    std                  | 0.184      |\n",
      "|    value_loss           | 0.000953   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 119296\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15610963 |\n",
      "|    clip_fraction        | 0.582      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.09       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0138     |\n",
      "|    n_updates            | 4660       |\n",
      "|    policy_gradient_loss | 0.0597     |\n",
      "|    std                  | 0.184      |\n",
      "|    value_loss           | 0.00088    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 119808\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.855      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16727237 |\n",
      "|    clip_fraction        | 0.618      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.07       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0426     |\n",
      "|    n_updates            | 4680       |\n",
      "|    policy_gradient_loss | 0.0515     |\n",
      "|    std                  | 0.184      |\n",
      "|    value_loss           | 0.000938   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 120320\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "seed 2: grid fidelity factor 1.0 learning ..\n",
      "environement grid size (nx x ny ): 31 x 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/ada_multigrid_ppo/utils/custom_eval_callback.py:106: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f41183c5470> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f40bc0bfcc0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2560, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.694      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17885463 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.05       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0532     |\n",
      "|    n_updates            | 4700       |\n",
      "|    policy_gradient_loss | 0.0555     |\n",
      "|    std                  | 0.184      |\n",
      "|    value_loss           | 0.000768   |\n",
      "----------------------------------------\n",
      "Early stopping at step 11 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 512\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.687     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1509872 |\n",
      "|    clip_fraction        | 0.504     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 5.92      |\n",
      "|    explained_variance   | -0.128    |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0169   |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -0.0409   |\n",
      "|    std                  | 0.182     |\n",
      "|    value_loss           | 0.0137    |\n",
      "---------------------------------------\n",
      "Early stopping at step 11 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 1024\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.72 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.718     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1517205 |\n",
      "|    clip_fraction        | 0.554     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 5.89      |\n",
      "|    explained_variance   | 0.837     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0593   |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0504   |\n",
      "|    std                  | 0.183     |\n",
      "|    value_loss           | 0.00437   |\n",
      "---------------------------------------\n",
      "Early stopping at step 17 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 1536\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.692      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16186786 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.95       |\n",
      "|    explained_variance   | 0.891      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0646    |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0564    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00396    |\n",
      "----------------------------------------\n",
      "Early stopping at step 10 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 2048\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.71 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.713      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15333672 |\n",
      "|    clip_fraction        | 0.571      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.99       |\n",
      "|    explained_variance   | 0.907      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0362    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0421    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00356    |\n",
      "----------------------------------------\n",
      "Early stopping at step 14 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 2560\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.71 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.706     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1588875 |\n",
      "|    clip_fraction        | 0.601     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.07      |\n",
      "|    explained_variance   | 0.915     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0382   |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -0.0531   |\n",
      "|    std                  | 0.181     |\n",
      "|    value_loss           | 0.00333   |\n",
      "---------------------------------------\n",
      "Early stopping at step 8 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 3072\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.72 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.723      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15134001 |\n",
      "|    clip_fraction        | 0.582      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.14       |\n",
      "|    explained_variance   | 0.923      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0466    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0384    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00325    |\n",
      "----------------------------------------\n",
      "Early stopping at step 7 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 3584\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.72 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.72       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15604267 |\n",
      "|    clip_fraction        | 0.576      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.16       |\n",
      "|    explained_variance   | 0.925      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0357    |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0395    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00314    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 7 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 4096\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.735     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 154       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1599662 |\n",
      "|    clip_fraction        | 0.57      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.19      |\n",
      "|    explained_variance   | 0.932     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0412   |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.0369   |\n",
      "|    std                  | 0.18      |\n",
      "|    value_loss           | 0.00301   |\n",
      "---------------------------------------\n",
      "Early stopping at step 7 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 4608\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.73 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.728      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15383735 |\n",
      "|    clip_fraction        | 0.57       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.17       |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.013      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00313    |\n",
      "----------------------------------------\n",
      "Early stopping at step 15 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 5120\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.736     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1709395 |\n",
      "|    clip_fraction        | 0.637     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.13      |\n",
      "|    explained_variance   | 0.931     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0666   |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -0.05     |\n",
      "|    std                  | 0.181     |\n",
      "|    value_loss           | 0.00295   |\n",
      "---------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 5632\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.737      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15508012 |\n",
      "|    clip_fraction        | 0.557      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.15       |\n",
      "|    explained_variance   | 0.933      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0119    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00272    |\n",
      "----------------------------------------\n",
      "Early stopping at step 8 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 6144\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.73 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.734      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15206724 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.13       |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0463    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0315    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00269    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 6656\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.743      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16153987 |\n",
      "|    clip_fraction        | 0.577      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.13       |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0346    |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00283    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 7168\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.739      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15541105 |\n",
      "|    clip_fraction        | 0.563      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.12       |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0481    |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.0027     |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 7680\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.74       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15047333 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.08       |\n",
      "|    explained_variance   | 0.942      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0219    |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00246    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 8192\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.745     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1543515 |\n",
      "|    clip_fraction        | 0.559     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.08      |\n",
      "|    explained_variance   | 0.942     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.00596  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -0.0138   |\n",
      "|    std                  | 0.181     |\n",
      "|    value_loss           | 0.00263   |\n",
      "---------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 8704\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.751      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15675119 |\n",
      "|    clip_fraction        | 0.595      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.12       |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0246    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00254    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 9216\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.76 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.76       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15495905 |\n",
      "|    clip_fraction        | 0.552      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.14       |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.000236  |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00253    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 9728\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.76 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.76       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16151193 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.16       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0364    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00258    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 10240\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.771      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15698135 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.14       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0289    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00249    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 10752\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.775      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15834226 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.14       |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0319    |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00238    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 11264\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.783      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15229227 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.12       |\n",
      "|    explained_variance   | 0.95       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0243     |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00243    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 11776\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.778      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16843231 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.15       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0393    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00724   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.0025     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 12288\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.777      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15667725 |\n",
      "|    clip_fraction        | 0.567      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.22       |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0154     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00196   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00266    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 12800\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.782      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15885144 |\n",
      "|    clip_fraction        | 0.579      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.22       |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0195    |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.00784   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00251    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 13312\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.782     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 148       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1614843 |\n",
      "|    clip_fraction        | 0.6       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.24      |\n",
      "|    explained_variance   | 0.954     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0347   |\n",
      "|    n_updates            | 520       |\n",
      "|    policy_gradient_loss | -0.0117   |\n",
      "|    std                  | 0.18      |\n",
      "|    value_loss           | 0.00223   |\n",
      "---------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 13824\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.782      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17164394 |\n",
      "|    clip_fraction        | 0.6        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.27       |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0405    |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.00846   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00246    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 14336\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.784      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15213723 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.28       |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0263    |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00246    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 14848\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.787      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15551865 |\n",
      "|    clip_fraction        | 0.61       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.27       |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0351    |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.00766   |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00229    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 15360\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.786      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16061528 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.27       |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0226     |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | 0.00685    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00222    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 15872\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.794      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15205984 |\n",
      "|    clip_fraction        | 0.594      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.28       |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0208     |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | 0.00339    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00239    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 16384\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.799      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15787064 |\n",
      "|    clip_fraction        | 0.598      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.29       |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00802    |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | 0.00873    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00228    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 16896\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.804      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15764424 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.29       |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0239     |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | 0.00895    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00211    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 17408\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.809      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18123622 |\n",
      "|    clip_fraction        | 0.61       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.3        |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0441     |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | 0.00244    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00203    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 17920\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.811      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15609016 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.32       |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00233   |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | 0.0058     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.00198    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 18432\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.813      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15211543 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.38       |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0263     |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | 0.000172   |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.00205    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 18944\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.816      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17080958 |\n",
      "|    clip_fraction        | 0.578      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.46       |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0337     |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | 0.0164     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00191    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 19456\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.822      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15858278 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.52       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0039    |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.000475  |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00188    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 19968\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.826      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15207191 |\n",
      "|    clip_fraction        | 0.624      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.61       |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0184    |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.00314   |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.0019     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 20480\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15540962 |\n",
      "|    clip_fraction        | 0.615      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.66       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0358    |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | 6.24e-05   |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00179    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 20992\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.831      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15247329 |\n",
      "|    clip_fraction        | 0.622      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.72       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0606    |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | 0.00714    |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00185    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 21504\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.833      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20344397 |\n",
      "|    clip_fraction        | 0.638      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.77       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0338     |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | 0.0179     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00195    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 22016\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.835      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15024051 |\n",
      "|    clip_fraction        | 0.623      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.85       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0596     |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | 0.00652    |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00154    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 22528\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.836     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 146       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1681159 |\n",
      "|    clip_fraction        | 0.616     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.95      |\n",
      "|    explained_variance   | 0.975     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.00487   |\n",
      "|    n_updates            | 880       |\n",
      "|    policy_gradient_loss | 0.00766   |\n",
      "|    std                  | 0.174     |\n",
      "|    value_loss           | 0.00147   |\n",
      "---------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 23040\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.838      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15963113 |\n",
      "|    clip_fraction        | 0.622      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.03       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00454    |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | 0.018      |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00143    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 23552\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.84       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16511284 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.06       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0799     |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | 0.0262     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00149    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 24064\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.843      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 144        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17337504 |\n",
      "|    clip_fraction        | 0.594      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.09       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00473    |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | 0.0276     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.00136    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 24576\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.844      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22424634 |\n",
      "|    clip_fraction        | 0.618      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.11       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0747     |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | 0.0458     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.00143    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 25088\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.846      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15359668 |\n",
      "|    clip_fraction        | 0.593      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.15       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00453   |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | 0.0203     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.00139    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 25600\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15161431 |\n",
      "|    clip_fraction        | 0.619      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.18       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0367     |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | 0.0178     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.0013     |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 26112\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.85      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1654713 |\n",
      "|    clip_fraction        | 0.592     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.19      |\n",
      "|    explained_variance   | 0.977     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.1       |\n",
      "|    n_updates            | 1020      |\n",
      "|    policy_gradient_loss | 0.0246    |\n",
      "|    std                  | 0.173     |\n",
      "|    value_loss           | 0.00139   |\n",
      "---------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 26624\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15215395 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.22       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | 0.03       |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.00123    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 27136\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.853      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16558874 |\n",
      "|    clip_fraction        | 0.643      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.21       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00872    |\n",
      "|    n_updates            | 1060       |\n",
      "|    policy_gradient_loss | 0.0204     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.00126    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 27648\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.854      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18057577 |\n",
      "|    clip_fraction        | 0.624      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.22       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00223   |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | 0.0325     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.00137    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 28160\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.856     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 145       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1743861 |\n",
      "|    clip_fraction        | 0.596     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.27      |\n",
      "|    explained_variance   | 0.984     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0648    |\n",
      "|    n_updates            | 1100      |\n",
      "|    policy_gradient_loss | 0.0478    |\n",
      "|    std                  | 0.172     |\n",
      "|    value_loss           | 0.00113   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 4 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 28672\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.856      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17363636 |\n",
      "|    clip_fraction        | 0.627      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.32       |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0147    |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | 0.0188     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.00124    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 29184\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.857      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16107306 |\n",
      "|    clip_fraction        | 0.586      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.38       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0925     |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | 0.0403     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.00108    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 29696\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.857      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19039643 |\n",
      "|    clip_fraction        | 0.595      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.44       |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0683     |\n",
      "|    n_updates            | 1160       |\n",
      "|    policy_gradient_loss | 0.0345     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 30208\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.858      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15864632 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.46       |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0423    |\n",
      "|    n_updates            | 1180       |\n",
      "|    policy_gradient_loss | 0.0512     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.0013     |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 30720\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.858      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18905921 |\n",
      "|    clip_fraction        | 0.611      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.51       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.196      |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | 0.0448     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.00119    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 31232\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.858     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1508009 |\n",
      "|    clip_fraction        | 0.577     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.56      |\n",
      "|    explained_variance   | 0.984     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.138     |\n",
      "|    n_updates            | 1220      |\n",
      "|    policy_gradient_loss | 0.0438    |\n",
      "|    std                  | 0.17      |\n",
      "|    value_loss           | 0.00114   |\n",
      "---------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 31744\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.859     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1611009 |\n",
      "|    clip_fraction        | 0.612     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.6       |\n",
      "|    explained_variance   | 0.986     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.018     |\n",
      "|    n_updates            | 1240      |\n",
      "|    policy_gradient_loss | 0.0333    |\n",
      "|    std                  | 0.169     |\n",
      "|    value_loss           | 0.000971  |\n",
      "---------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 32256\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.859      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15468374 |\n",
      "|    clip_fraction        | 0.64       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.67       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0269     |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | 0.0198     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.00101    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 32768\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.86       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16322204 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.69       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.068      |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | 0.0346     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000941   |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 33280\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.86       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16379999 |\n",
      "|    clip_fraction        | 0.624      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.68       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0763     |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | 0.0274     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.00104    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 33792\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.859      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18093601 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.68       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.204      |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | 0.0537     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.00106    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 34304\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.86       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16207866 |\n",
      "|    clip_fraction        | 0.616      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.71       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0908     |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | 0.0279     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000927   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 34816\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.86       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16357334 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.74       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0591     |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | 0.0385     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000795   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 35328\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.861      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17388514 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.76       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00279    |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | 0.0302     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.00114    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 35840\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.862      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17119534 |\n",
      "|    clip_fraction        | 0.602      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.8        |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0112     |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | 0.0451     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.00102    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 36352\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.862     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1875531 |\n",
      "|    clip_fraction        | 0.625     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.77      |\n",
      "|    explained_variance   | 0.985     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0449    |\n",
      "|    n_updates            | 1420      |\n",
      "|    policy_gradient_loss | 0.0341    |\n",
      "|    std                  | 0.169     |\n",
      "|    value_loss           | 0.000902  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 36864\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.864      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15087953 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.77       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0408     |\n",
      "|    n_updates            | 1440       |\n",
      "|    policy_gradient_loss | 0.0437     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.001      |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 37376\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.865      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15356591 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.79       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00524    |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | 0.0546     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000817   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 37888\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.865      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16228053 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.78       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0686     |\n",
      "|    n_updates            | 1480       |\n",
      "|    policy_gradient_loss | 0.0256     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000906   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 38400\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.867      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18195303 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.8        |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0027    |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | 0.0375     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.00085    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 38912\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.867      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15608855 |\n",
      "|    clip_fraction        | 0.63       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00605    |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | 0.0158     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000869   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 39424\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.867     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1654038 |\n",
      "|    clip_fraction        | 0.608     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.81      |\n",
      "|    explained_variance   | 0.991     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0779    |\n",
      "|    n_updates            | 1540      |\n",
      "|    policy_gradient_loss | 0.0511    |\n",
      "|    std                  | 0.169     |\n",
      "|    value_loss           | 0.000726  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 39936\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.869      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16557427 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.8        |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0882     |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | 0.0462     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000807   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 40448\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.87       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15434697 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.81       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0281     |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | 0.0398     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000819   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 7 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 40960\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.871      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16788384 |\n",
      "|    clip_fraction        | 0.643      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.78       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0293    |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | 0.0195     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000694   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 41472\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.872      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17040132 |\n",
      "|    clip_fraction        | 0.581      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.77       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0665     |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | 0.0463     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000738   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 41984\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.873      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16016217 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.77       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.15       |\n",
      "|    n_updates            | 1640       |\n",
      "|    policy_gradient_loss | 0.0491     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000839   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 42496\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.873      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15407549 |\n",
      "|    clip_fraction        | 0.629      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.78       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0846     |\n",
      "|    n_updates            | 1660       |\n",
      "|    policy_gradient_loss | 0.0574     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000695   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 43008\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.873      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15824895 |\n",
      "|    clip_fraction        | 0.581      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.83       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.179      |\n",
      "|    n_updates            | 1680       |\n",
      "|    policy_gradient_loss | 0.0563     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000719   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 43520\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.873     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1596209 |\n",
      "|    clip_fraction        | 0.629     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.85      |\n",
      "|    explained_variance   | 0.991     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0758    |\n",
      "|    n_updates            | 1700      |\n",
      "|    policy_gradient_loss | 0.0501    |\n",
      "|    std                  | 0.168     |\n",
      "|    value_loss           | 0.000734  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 44032\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.874      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15645607 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.86       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0603     |\n",
      "|    n_updates            | 1720       |\n",
      "|    policy_gradient_loss | 0.0454     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000683   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 44544\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.874      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15878126 |\n",
      "|    clip_fraction        | 0.582      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.86       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.000743   |\n",
      "|    n_updates            | 1740       |\n",
      "|    policy_gradient_loss | 0.0594     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000792   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 45056\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.875      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19581237 |\n",
      "|    clip_fraction        | 0.61       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.84       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0784     |\n",
      "|    n_updates            | 1760       |\n",
      "|    policy_gradient_loss | 0.0433     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000827   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.23\n",
      "\n",
      "Total episode rollouts: 45568\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.874      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22515738 |\n",
      "|    clip_fraction        | 0.598      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.85       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0974     |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | 0.0574     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000716   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 46080\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.875     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 155       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1555439 |\n",
      "|    clip_fraction        | 0.608     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.88      |\n",
      "|    explained_variance   | 0.991     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0311    |\n",
      "|    n_updates            | 1800      |\n",
      "|    policy_gradient_loss | 0.0525    |\n",
      "|    std                  | 0.168     |\n",
      "|    value_loss           | 0.000705  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 46592\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.876      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15624562 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.86       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.147      |\n",
      "|    n_updates            | 1820       |\n",
      "|    policy_gradient_loss | 0.0353     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000681   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 47104\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.877      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16177943 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.85       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00788    |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | 0.0383     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000685   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 47616\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.877      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17263702 |\n",
      "|    clip_fraction        | 0.576      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.89       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.108      |\n",
      "|    n_updates            | 1860       |\n",
      "|    policy_gradient_loss | 0.0507     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.00091    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 48128\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.877     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1950847 |\n",
      "|    clip_fraction        | 0.637     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.93      |\n",
      "|    explained_variance   | 0.991     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.108     |\n",
      "|    n_updates            | 1880      |\n",
      "|    policy_gradient_loss | 0.0617    |\n",
      "|    std                  | 0.168     |\n",
      "|    value_loss           | 0.000661  |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 48640\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.877      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15237233 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.95       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.14       |\n",
      "|    n_updates            | 1900       |\n",
      "|    policy_gradient_loss | 0.0519     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000745   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 49152\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.877      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18167345 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.96       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.03       |\n",
      "|    n_updates            | 1920       |\n",
      "|    policy_gradient_loss | 0.0491     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.00059    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 49664\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.878      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15048978 |\n",
      "|    clip_fraction        | 0.586      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.97       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00337    |\n",
      "|    n_updates            | 1940       |\n",
      "|    policy_gradient_loss | 0.0376     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000623   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 50176\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.878      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17525417 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.97       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.148      |\n",
      "|    n_updates            | 1960       |\n",
      "|    policy_gradient_loss | 0.0566     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000657   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 50688\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.877      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16983643 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.01       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0765     |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | 0.0686     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000899   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 51200\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.878      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21869178 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.01       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.192      |\n",
      "|    n_updates            | 2000       |\n",
      "|    policy_gradient_loss | 0.0633     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000565   |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 51712\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.878      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16585706 |\n",
      "|    clip_fraction        | 0.628      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.98       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0392     |\n",
      "|    n_updates            | 2020       |\n",
      "|    policy_gradient_loss | 0.0456     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000681   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 52224\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.878      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16312619 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.92       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0375     |\n",
      "|    n_updates            | 2040       |\n",
      "|    policy_gradient_loss | 0.0429     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000601   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 52736\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.878     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1512154 |\n",
      "|    clip_fraction        | 0.609     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.89      |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0427    |\n",
      "|    n_updates            | 2060      |\n",
      "|    policy_gradient_loss | 0.0483    |\n",
      "|    std                  | 0.169     |\n",
      "|    value_loss           | 0.000728  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 53248\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15152326 |\n",
      "|    clip_fraction        | 0.629      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.89       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.139      |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | 0.037      |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.00065    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 53760\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15510997 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.91       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.022      |\n",
      "|    n_updates            | 2100       |\n",
      "|    policy_gradient_loss | 0.0517     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.00071    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 54272\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.879     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1791416 |\n",
      "|    clip_fraction        | 0.636     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.91      |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0412    |\n",
      "|    n_updates            | 2120      |\n",
      "|    policy_gradient_loss | 0.0545    |\n",
      "|    std                  | 0.168     |\n",
      "|    value_loss           | 0.000687  |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 54784\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18497124 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.91       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0121     |\n",
      "|    n_updates            | 2140       |\n",
      "|    policy_gradient_loss | 0.0602     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000857   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 55296\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15547702 |\n",
      "|    clip_fraction        | 0.629      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.9        |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00938    |\n",
      "|    n_updates            | 2160       |\n",
      "|    policy_gradient_loss | 0.0561     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000941   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 55808\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19728589 |\n",
      "|    clip_fraction        | 0.6        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.91       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.128      |\n",
      "|    n_updates            | 2180       |\n",
      "|    policy_gradient_loss | 0.0608     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000682   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 56320\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.879     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1904734 |\n",
      "|    clip_fraction        | 0.606     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.94      |\n",
      "|    explained_variance   | 0.989     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0591    |\n",
      "|    n_updates            | 2200      |\n",
      "|    policy_gradient_loss | 0.0473    |\n",
      "|    std                  | 0.168     |\n",
      "|    value_loss           | 0.000692  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 56832\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20211391 |\n",
      "|    clip_fraction        | 0.616      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.98       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.135      |\n",
      "|    n_updates            | 2220       |\n",
      "|    policy_gradient_loss | 0.0395     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000884   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 57344\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17185768 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.99       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0086    |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | 0.0543     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000858   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 57856\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15630718 |\n",
      "|    clip_fraction        | 0.57       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.01       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.107      |\n",
      "|    n_updates            | 2260       |\n",
      "|    policy_gradient_loss | 0.0536     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000768   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 58368\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16138215 |\n",
      "|    clip_fraction        | 0.593      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.02       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0442     |\n",
      "|    n_updates            | 2280       |\n",
      "|    policy_gradient_loss | 0.059      |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000823   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 58880\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17628497 |\n",
      "|    clip_fraction        | 0.623      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.04       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.112      |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | 0.0449     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000668   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 59392\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16601117 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.06       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.000952  |\n",
      "|    n_updates            | 2320       |\n",
      "|    policy_gradient_loss | 0.0392     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000661   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 59904\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15541399 |\n",
      "|    clip_fraction        | 0.594      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.07       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0287     |\n",
      "|    n_updates            | 2340       |\n",
      "|    policy_gradient_loss | 0.0529     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000616   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 60416\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19694266 |\n",
      "|    clip_fraction        | 0.602      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.07       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.227      |\n",
      "|    n_updates            | 2360       |\n",
      "|    policy_gradient_loss | 0.0617     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000716   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 60928\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17628498 |\n",
      "|    clip_fraction        | 0.609      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.11       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0629     |\n",
      "|    n_updates            | 2380       |\n",
      "|    policy_gradient_loss | 0.0606     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000757   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 61440\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15234956 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.09       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0708     |\n",
      "|    n_updates            | 2400       |\n",
      "|    policy_gradient_loss | 0.053      |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000644   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 61952\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18079484 |\n",
      "|    clip_fraction        | 0.612      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.08       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.177      |\n",
      "|    n_updates            | 2420       |\n",
      "|    policy_gradient_loss | 0.064      |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000683   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 62464\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15192409 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.09       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0372     |\n",
      "|    n_updates            | 2440       |\n",
      "|    policy_gradient_loss | 0.045      |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000675   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 62976\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16390169 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.08       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0914     |\n",
      "|    n_updates            | 2460       |\n",
      "|    policy_gradient_loss | 0.0618     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000705   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 63488\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.879     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1932132 |\n",
      "|    clip_fraction        | 0.598     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 8.09      |\n",
      "|    explained_variance   | 0.991     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.154     |\n",
      "|    n_updates            | 2480      |\n",
      "|    policy_gradient_loss | 0.0691    |\n",
      "|    std                  | 0.167     |\n",
      "|    value_loss           | 0.000747  |\n",
      "---------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 64000\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.879     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 154       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1565268 |\n",
      "|    clip_fraction        | 0.624     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 8.09      |\n",
      "|    explained_variance   | 0.991     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0453   |\n",
      "|    n_updates            | 2500      |\n",
      "|    policy_gradient_loss | 0.0315    |\n",
      "|    std                  | 0.167     |\n",
      "|    value_loss           | 0.000594  |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 64512\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20691831 |\n",
      "|    clip_fraction        | 0.633      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.1        |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.135      |\n",
      "|    n_updates            | 2520       |\n",
      "|    policy_gradient_loss | 0.0701     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000859   |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 65024\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15335366 |\n",
      "|    clip_fraction        | 0.645      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.1        |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0071    |\n",
      "|    n_updates            | 2540       |\n",
      "|    policy_gradient_loss | 0.043      |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000687   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 65536\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16928832 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.09       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0628     |\n",
      "|    n_updates            | 2560       |\n",
      "|    policy_gradient_loss | 0.0499     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000674   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 66048\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15429552 |\n",
      "|    clip_fraction        | 0.63       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.09       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0654     |\n",
      "|    n_updates            | 2580       |\n",
      "|    policy_gradient_loss | 0.041      |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000665   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 66560\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17459561 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.09       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0113     |\n",
      "|    n_updates            | 2600       |\n",
      "|    policy_gradient_loss | 0.0448     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000651   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 67072\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16757914 |\n",
      "|    clip_fraction        | 0.598      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.09       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.183      |\n",
      "|    n_updates            | 2620       |\n",
      "|    policy_gradient_loss | 0.0582     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.00077    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 67584\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16485193 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.1        |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00883    |\n",
      "|    n_updates            | 2640       |\n",
      "|    policy_gradient_loss | 0.0579     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000881   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 68096\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19303998 |\n",
      "|    clip_fraction        | 0.624      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.07       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0317     |\n",
      "|    n_updates            | 2660       |\n",
      "|    policy_gradient_loss | 0.0706     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000709   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 68608\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17351036 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.06       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0811     |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | 0.0704     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000774   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 69120\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17230049 |\n",
      "|    clip_fraction        | 0.602      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.06       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.162      |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | 0.0562     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000574   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 69632\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21964207 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.06       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00121   |\n",
      "|    n_updates            | 2720       |\n",
      "|    policy_gradient_loss | 0.0713     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.00067    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 70144\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16859981 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.08       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00701    |\n",
      "|    n_updates            | 2740       |\n",
      "|    policy_gradient_loss | 0.0635     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000659   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 70656\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20064318 |\n",
      "|    clip_fraction        | 0.62       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.08       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0368     |\n",
      "|    n_updates            | 2760       |\n",
      "|    policy_gradient_loss | 0.0682     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000599   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 71168\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16391921 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.08       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0676     |\n",
      "|    n_updates            | 2780       |\n",
      "|    policy_gradient_loss | 0.07       |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000665   |\n",
      "----------------------------------------\n",
      "Early stopping at step 8 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 71680\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16293049 |\n",
      "|    clip_fraction        | 0.669      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.07       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.112      |\n",
      "|    n_updates            | 2800       |\n",
      "|    policy_gradient_loss | 0.022      |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000579   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.25\n",
      "\n",
      "Total episode rollouts: 72192\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24969006 |\n",
      "|    clip_fraction        | 0.629      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.07       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0677     |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | 0.0882     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 0.000708   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 72704\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15291026 |\n",
      "|    clip_fraction        | 0.63       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.03       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0461     |\n",
      "|    n_updates            | 2840       |\n",
      "|    policy_gradient_loss | 0.0473     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000622   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 73216\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1501444 |\n",
      "|    clip_fraction        | 0.596     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.96      |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0319    |\n",
      "|    n_updates            | 2860      |\n",
      "|    policy_gradient_loss | 0.0497    |\n",
      "|    std                  | 0.168     |\n",
      "|    value_loss           | 0.000584  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 73728\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16839425 |\n",
      "|    clip_fraction        | 0.619      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.93       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00198    |\n",
      "|    n_updates            | 2880       |\n",
      "|    policy_gradient_loss | 0.0706     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000602   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 74240\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18327469 |\n",
      "|    clip_fraction        | 0.607      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.93       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0624     |\n",
      "|    n_updates            | 2900       |\n",
      "|    policy_gradient_loss | 0.0529     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000673   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 74752\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17913313 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.94       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00489   |\n",
      "|    n_updates            | 2920       |\n",
      "|    policy_gradient_loss | 0.0458     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000574   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 75264\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18948586 |\n",
      "|    clip_fraction        | 0.615      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.95       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0135    |\n",
      "|    n_updates            | 2940       |\n",
      "|    policy_gradient_loss | 0.065      |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000733   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 75776\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18134683 |\n",
      "|    clip_fraction        | 0.592      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.97       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 2960       |\n",
      "|    policy_gradient_loss | 0.0515     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000616   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 76288\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21837337 |\n",
      "|    clip_fraction        | 0.637      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.94       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0244     |\n",
      "|    n_updates            | 2980       |\n",
      "|    policy_gradient_loss | 0.0801     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000715   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 76800\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17674217 |\n",
      "|    clip_fraction        | 0.578      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.93       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0698     |\n",
      "|    n_updates            | 3000       |\n",
      "|    policy_gradient_loss | 0.0432     |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 0.000635   |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 77312\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15770626 |\n",
      "|    clip_fraction        | 0.623      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.91       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0569     |\n",
      "|    n_updates            | 3020       |\n",
      "|    policy_gradient_loss | 0.0326     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000629   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 77824\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20575733 |\n",
      "|    clip_fraction        | 0.61       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.88       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0717     |\n",
      "|    n_updates            | 3040       |\n",
      "|    policy_gradient_loss | 0.0619     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000575   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 78336\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17036667 |\n",
      "|    clip_fraction        | 0.598      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.91       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0466     |\n",
      "|    n_updates            | 3060       |\n",
      "|    policy_gradient_loss | 0.0588     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000619   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 78848\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17477834 |\n",
      "|    clip_fraction        | 0.619      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.94       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.142      |\n",
      "|    n_updates            | 3080       |\n",
      "|    policy_gradient_loss | 0.0641     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000576   |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 79360\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16574058 |\n",
      "|    clip_fraction        | 0.637      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.91       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 3100       |\n",
      "|    policy_gradient_loss | 0.0387     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000602   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 79872\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17375222 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.89       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0903     |\n",
      "|    n_updates            | 3120       |\n",
      "|    policy_gradient_loss | 0.0603     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000657   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 80384\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15710735 |\n",
      "|    clip_fraction        | 0.611      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.87       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0244     |\n",
      "|    n_updates            | 3140       |\n",
      "|    policy_gradient_loss | 0.0527     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000613   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 80896\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17661758 |\n",
      "|    clip_fraction        | 0.63       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.83       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.115      |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | 0.0385     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000637   |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 81408\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.881     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1562905 |\n",
      "|    clip_fraction        | 0.635     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.83      |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.108     |\n",
      "|    n_updates            | 3180      |\n",
      "|    policy_gradient_loss | 0.0431    |\n",
      "|    std                  | 0.169     |\n",
      "|    value_loss           | 0.000612  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 81920\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17078471 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00924    |\n",
      "|    n_updates            | 3200       |\n",
      "|    policy_gradient_loss | 0.0619     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000655   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 82432\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.881     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1722813 |\n",
      "|    clip_fraction        | 0.62      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.78      |\n",
      "|    explained_variance   | 0.993     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0469    |\n",
      "|    n_updates            | 3220      |\n",
      "|    policy_gradient_loss | 0.0417    |\n",
      "|    std                  | 0.17      |\n",
      "|    value_loss           | 0.000588  |\n",
      "---------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 82944\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21756148 |\n",
      "|    clip_fraction        | 0.661      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.76       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0796     |\n",
      "|    n_updates            | 3240       |\n",
      "|    policy_gradient_loss | 0.0348     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000544   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 83456\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18276086 |\n",
      "|    clip_fraction        | 0.598      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.76       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 3260       |\n",
      "|    policy_gradient_loss | 0.0463     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000522   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 83968\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.881     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1657038 |\n",
      "|    clip_fraction        | 0.608     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.79      |\n",
      "|    explained_variance   | 0.993     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.00198  |\n",
      "|    n_updates            | 3280      |\n",
      "|    policy_gradient_loss | 0.0495    |\n",
      "|    std                  | 0.17      |\n",
      "|    value_loss           | 0.000583  |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 84480\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19455874 |\n",
      "|    clip_fraction        | 0.61       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0193     |\n",
      "|    n_updates            | 3300       |\n",
      "|    policy_gradient_loss | 0.06       |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000572   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 84992\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15250142 |\n",
      "|    clip_fraction        | 0.615      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.153      |\n",
      "|    n_updates            | 3320       |\n",
      "|    policy_gradient_loss | 0.0554     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000517   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 85504\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 5        |\n",
      "|    mean_reward          | 0.881    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 151      |\n",
      "|    iterations           | 1        |\n",
      "|    time_elapsed         | 16       |\n",
      "|    total_timesteps      | 2560     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.157612 |\n",
      "|    clip_fraction        | 0.621    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 7.81     |\n",
      "|    explained_variance   | 0.992    |\n",
      "|    learning_rate        | 0.0005   |\n",
      "|    loss                 | 0.0319   |\n",
      "|    n_updates            | 3340     |\n",
      "|    policy_gradient_loss | 0.0454   |\n",
      "|    std                  | 0.17     |\n",
      "|    value_loss           | 0.000548 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 9 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 86016\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15313362 |\n",
      "|    clip_fraction        | 0.651      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.84       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0151     |\n",
      "|    n_updates            | 3360       |\n",
      "|    policy_gradient_loss | 0.0234     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000558   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 86528\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19414847 |\n",
      "|    clip_fraction        | 0.592      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.88       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00381   |\n",
      "|    n_updates            | 3380       |\n",
      "|    policy_gradient_loss | 0.0572     |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 0.000547   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 87040\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16811374 |\n",
      "|    clip_fraction        | 0.624      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.88       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0633     |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | 0.0726     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.00056    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 87552\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16634627 |\n",
      "|    clip_fraction        | 0.581      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.88       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.156      |\n",
      "|    n_updates            | 3420       |\n",
      "|    policy_gradient_loss | 0.0692     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000597   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 88064\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19021705 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.88       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0654     |\n",
      "|    n_updates            | 3440       |\n",
      "|    policy_gradient_loss | 0.0848     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.00067    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 88576\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15045403 |\n",
      "|    clip_fraction        | 0.619      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.85       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 3460       |\n",
      "|    policy_gradient_loss | 0.0518     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000654   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 89088\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16564885 |\n",
      "|    clip_fraction        | 0.643      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.85       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0183     |\n",
      "|    n_updates            | 3480       |\n",
      "|    policy_gradient_loss | 0.0522     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000596   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 89600\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.881      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16038918 |\n",
      "|    clip_fraction        | 0.564      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.87       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0342     |\n",
      "|    n_updates            | 3500       |\n",
      "|    policy_gradient_loss | 0.0534     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.00057    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 6 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 90112\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16016154 |\n",
      "|    clip_fraction        | 0.643      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.87       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0047    |\n",
      "|    n_updates            | 3520       |\n",
      "|    policy_gradient_loss | 0.0261     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000569   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 90624\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15576498 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.88       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0562     |\n",
      "|    n_updates            | 3540       |\n",
      "|    policy_gradient_loss | 0.0406     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000574   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 91136\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16382445 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.88       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0799     |\n",
      "|    n_updates            | 3560       |\n",
      "|    policy_gradient_loss | 0.0564     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000649   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 91648\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15560207 |\n",
      "|    clip_fraction        | 0.593      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.86       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0245     |\n",
      "|    n_updates            | 3580       |\n",
      "|    policy_gradient_loss | 0.0334     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000554   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 92160\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16461438 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.86       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 3600       |\n",
      "|    policy_gradient_loss | 0.049      |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000558   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 92672\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17391095 |\n",
      "|    clip_fraction        | 0.618      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.84       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.136      |\n",
      "|    n_updates            | 3620       |\n",
      "|    policy_gradient_loss | 0.0707     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000492   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 93184\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 148       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1886468 |\n",
      "|    clip_fraction        | 0.598     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.83      |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0861    |\n",
      "|    n_updates            | 3640      |\n",
      "|    policy_gradient_loss | 0.0653    |\n",
      "|    std                  | 0.17      |\n",
      "|    value_loss           | 0.000624  |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 93696\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15647916 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0154    |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | 0.0528     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000596   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 94208\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15994406 |\n",
      "|    clip_fraction        | 0.631      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.81       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.095      |\n",
      "|    n_updates            | 3680       |\n",
      "|    policy_gradient_loss | 0.0439     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000614   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 94720\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16630688 |\n",
      "|    clip_fraction        | 0.643      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.81       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0535     |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | 0.0425     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000601   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 95232\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15111752 |\n",
      "|    clip_fraction        | 0.628      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0781     |\n",
      "|    n_updates            | 3720       |\n",
      "|    policy_gradient_loss | 0.0444     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000545   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 95744\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17804968 |\n",
      "|    clip_fraction        | 0.618      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00675   |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | 0.0511     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000683   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 96256\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20681751 |\n",
      "|    clip_fraction        | 0.619      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.85       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0645     |\n",
      "|    n_updates            | 3760       |\n",
      "|    policy_gradient_loss | 0.0467     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.00064    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 96768\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19018522 |\n",
      "|    clip_fraction        | 0.609      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.86       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0833     |\n",
      "|    n_updates            | 3780       |\n",
      "|    policy_gradient_loss | 0.0621     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000713   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 97280\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16210333 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.87       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.117      |\n",
      "|    n_updates            | 3800       |\n",
      "|    policy_gradient_loss | 0.0457     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000545   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 97792\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15666373 |\n",
      "|    clip_fraction        | 0.576      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.89       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0539     |\n",
      "|    n_updates            | 3820       |\n",
      "|    policy_gradient_loss | 0.0513     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000584   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 98304\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16231982 |\n",
      "|    clip_fraction        | 0.622      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.87       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0373     |\n",
      "|    n_updates            | 3840       |\n",
      "|    policy_gradient_loss | 0.0609     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000593   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 98816\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17475045 |\n",
      "|    clip_fraction        | 0.612      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.83       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0374     |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | 0.0694     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000674   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.21\n",
      "\n",
      "Total episode rollouts: 99328\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20525412 |\n",
      "|    clip_fraction        | 0.592      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.83       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0397    |\n",
      "|    n_updates            | 3880       |\n",
      "|    policy_gradient_loss | 0.0467     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000634   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 99840\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18072799 |\n",
      "|    clip_fraction        | 0.626      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.138      |\n",
      "|    n_updates            | 3900       |\n",
      "|    policy_gradient_loss | 0.0501     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000561   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 100352\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15484683 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.81       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0254     |\n",
      "|    n_updates            | 3920       |\n",
      "|    policy_gradient_loss | 0.0456     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000592   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 100864\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16457239 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.8        |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.289      |\n",
      "|    n_updates            | 3940       |\n",
      "|    policy_gradient_loss | 0.0728     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.00054    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 101376\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17978498 |\n",
      "|    clip_fraction        | 0.622      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.78       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.032      |\n",
      "|    n_updates            | 3960       |\n",
      "|    policy_gradient_loss | 0.0469     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000587   |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 101888\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15163848 |\n",
      "|    clip_fraction        | 0.633      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.79       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0383     |\n",
      "|    n_updates            | 3980       |\n",
      "|    policy_gradient_loss | 0.0314     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000546   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 102400\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15034151 |\n",
      "|    clip_fraction        | 0.602      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.81       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0684     |\n",
      "|    n_updates            | 4000       |\n",
      "|    policy_gradient_loss | 0.0589     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000578   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 102912\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16859612 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.81       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.18       |\n",
      "|    n_updates            | 4020       |\n",
      "|    policy_gradient_loss | 0.0645     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000562   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 103424\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 144        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16737738 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.82       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0512     |\n",
      "|    n_updates            | 4040       |\n",
      "|    policy_gradient_loss | 0.0638     |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 0.000575   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 103936\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 154       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1505171 |\n",
      "|    clip_fraction        | 0.622     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.8       |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.2       |\n",
      "|    n_updates            | 4060      |\n",
      "|    policy_gradient_loss | 0.051     |\n",
      "|    std                  | 0.171     |\n",
      "|    value_loss           | 0.000601  |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 104448\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15715864 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.79       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00771    |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | 0.054      |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000577   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 104960\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15175577 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.77       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0385     |\n",
      "|    n_updates            | 4100       |\n",
      "|    policy_gradient_loss | 0.0587     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.00055    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 105472\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 148       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1829758 |\n",
      "|    clip_fraction        | 0.616     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.75      |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.102     |\n",
      "|    n_updates            | 4120      |\n",
      "|    policy_gradient_loss | 0.0625    |\n",
      "|    std                  | 0.171     |\n",
      "|    value_loss           | 0.000697  |\n",
      "---------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 105984\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15434957 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.75       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.102      |\n",
      "|    n_updates            | 4140       |\n",
      "|    policy_gradient_loss | 0.0412     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000575   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 106496\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17532834 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.74       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0648     |\n",
      "|    n_updates            | 4160       |\n",
      "|    policy_gradient_loss | 0.0453     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000623   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 107008\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18813142 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.74       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0453     |\n",
      "|    n_updates            | 4180       |\n",
      "|    policy_gradient_loss | 0.0526     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000537   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 107520\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15053438 |\n",
      "|    clip_fraction        | 0.594      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.72       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.089      |\n",
      "|    n_updates            | 4200       |\n",
      "|    policy_gradient_loss | 0.0487     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000514   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 108032\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18489823 |\n",
      "|    clip_fraction        | 0.611      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.72       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 4220       |\n",
      "|    policy_gradient_loss | 0.0419     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.00051    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 108544\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18363701 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.7        |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0403     |\n",
      "|    n_updates            | 4240       |\n",
      "|    policy_gradient_loss | 0.0711     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000533   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 109056\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15554278 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.67       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0579     |\n",
      "|    n_updates            | 4260       |\n",
      "|    policy_gradient_loss | 0.0619     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000577   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 109568\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16784878 |\n",
      "|    clip_fraction        | 0.616      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.68       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0665     |\n",
      "|    n_updates            | 4280       |\n",
      "|    policy_gradient_loss | 0.0478     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000523   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 110080\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19714747 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.7        |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0949     |\n",
      "|    n_updates            | 4300       |\n",
      "|    policy_gradient_loss | 0.0546     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000574   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 110592\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16836476 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.68       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0149     |\n",
      "|    n_updates            | 4320       |\n",
      "|    policy_gradient_loss | 0.0505     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000611   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 111104\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18338951 |\n",
      "|    clip_fraction        | 0.594      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.64       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.017      |\n",
      "|    n_updates            | 4340       |\n",
      "|    policy_gradient_loss | 0.0539     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000592   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 111616\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18830141 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.6        |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.014     |\n",
      "|    n_updates            | 4360       |\n",
      "|    policy_gradient_loss | 0.0356     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000508   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 112128\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18595465 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.57       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0251     |\n",
      "|    n_updates            | 4380       |\n",
      "|    policy_gradient_loss | 0.0562     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.000505   |\n",
      "----------------------------------------\n",
      "Early stopping at step 11 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 112640\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16979155 |\n",
      "|    clip_fraction        | 0.66       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.57       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0206    |\n",
      "|    n_updates            | 4400       |\n",
      "|    policy_gradient_loss | 0.0209     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000523   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 113152\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1815916 |\n",
      "|    clip_fraction        | 0.6       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.59      |\n",
      "|    explained_variance   | 0.994     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.131     |\n",
      "|    n_updates            | 4420      |\n",
      "|    policy_gradient_loss | 0.0625    |\n",
      "|    std                  | 0.172     |\n",
      "|    value_loss           | 0.000483  |\n",
      "---------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 113664\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19275537 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.61       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.204      |\n",
      "|    n_updates            | 4440       |\n",
      "|    policy_gradient_loss | 0.0509     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000476   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.19\n",
      "\n",
      "Total episode rollouts: 114176\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18703948 |\n",
      "|    clip_fraction        | 0.611      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.64       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0804     |\n",
      "|    n_updates            | 4460       |\n",
      "|    policy_gradient_loss | 0.0523     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000534   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 114688\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16499186 |\n",
      "|    clip_fraction        | 0.615      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.67       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0464     |\n",
      "|    n_updates            | 4480       |\n",
      "|    policy_gradient_loss | 0.0423     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000552   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.22\n",
      "\n",
      "Total episode rollouts: 115200\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21884207 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.71       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.223      |\n",
      "|    n_updates            | 4500       |\n",
      "|    policy_gradient_loss | 0.063      |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000511   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 115712\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.879      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16801801 |\n",
      "|    clip_fraction        | 0.616      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.7        |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.124      |\n",
      "|    n_updates            | 4520       |\n",
      "|    policy_gradient_loss | 0.0613     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000517   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 116224\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15245701 |\n",
      "|    clip_fraction        | 0.6        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.67       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.12       |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | 0.0548     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000489   |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 116736\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16987206 |\n",
      "|    clip_fraction        | 0.583      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.65       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0517     |\n",
      "|    n_updates            | 4560       |\n",
      "|    policy_gradient_loss | 0.0524     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000474   |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 117248\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15305614 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.67       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.1        |\n",
      "|    n_updates            | 4580       |\n",
      "|    policy_gradient_loss | 0.0365     |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.000489   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 117760\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1731346 |\n",
      "|    clip_fraction        | 0.608     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.69      |\n",
      "|    explained_variance   | 0.994     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0432    |\n",
      "|    n_updates            | 4600      |\n",
      "|    policy_gradient_loss | 0.0513    |\n",
      "|    std                  | 0.171     |\n",
      "|    value_loss           | 0.000494  |\n",
      "---------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 118272\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17369294 |\n",
      "|    clip_fraction        | 0.648      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.68       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0865     |\n",
      "|    n_updates            | 4620       |\n",
      "|    policy_gradient_loss | 0.0455     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.00053    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 118784\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15889768 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.66       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0369     |\n",
      "|    n_updates            | 4640       |\n",
      "|    policy_gradient_loss | 0.0375     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000541   |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 119296\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1540269 |\n",
      "|    clip_fraction        | 0.648     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.6       |\n",
      "|    explained_variance   | 0.993     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0244    |\n",
      "|    n_updates            | 4660      |\n",
      "|    policy_gradient_loss | 0.0327    |\n",
      "|    std                  | 0.172     |\n",
      "|    value_loss           | 0.000534  |\n",
      "---------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 119808\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17592558 |\n",
      "|    clip_fraction        | 0.629      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.58       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.022      |\n",
      "|    n_updates            | 4680       |\n",
      "|    policy_gradient_loss | 0.058      |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000551   |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 120320\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "seed 3: grid fidelity factor 1.0 learning ..\n",
      "environement grid size (nx x ny ): 31 x 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/ada_multigrid_ppo/utils/custom_eval_callback.py:106: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f40bc09a320> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f40bc09a908>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2560, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.695      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 131        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15283477 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.56       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0219     |\n",
      "|    n_updates            | 4700       |\n",
      "|    policy_gradient_loss | 0.0524     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.000518   |\n",
      "----------------------------------------\n",
      "Early stopping at step 8 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 512\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.693      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17254637 |\n",
      "|    clip_fraction        | 0.508      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.91       |\n",
      "|    explained_variance   | -0.45      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0602    |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.0166     |\n",
      "----------------------------------------\n",
      "Early stopping at step 12 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 1024\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.71 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.71       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15250115 |\n",
      "|    clip_fraction        | 0.54       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.96       |\n",
      "|    explained_variance   | 0.837      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0393    |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0501    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00451    |\n",
      "----------------------------------------\n",
      "Early stopping at step 18 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 1536\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.72 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.72       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 144        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15140426 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.98       |\n",
      "|    explained_variance   | 0.9        |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0685    |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0564    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 0.00384    |\n",
      "----------------------------------------\n",
      "Early stopping at step 16 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 2048\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.71 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.713      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15351713 |\n",
      "|    clip_fraction        | 0.584      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.02       |\n",
      "|    explained_variance   | 0.922      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0867    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0581    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00327    |\n",
      "----------------------------------------\n",
      "Early stopping at step 10 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 2560\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.71 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.706      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 146        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15795788 |\n",
      "|    clip_fraction        | 0.572      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.08       |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0324    |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0451    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00315    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 3072\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.72 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.716      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15013364 |\n",
      "|    clip_fraction        | 0.563      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.06       |\n",
      "|    explained_variance   | 0.912      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0359    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00317    |\n",
      "----------------------------------------\n",
      "Early stopping at step 10 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 3584\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.736      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16115323 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.1        |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0462    |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00282    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 11 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 4096\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.736      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15798809 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.11       |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0658    |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0471    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.0027     |\n",
      "----------------------------------------\n",
      "Early stopping at step 7 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 4608\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.737      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16239259 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.11       |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0497    |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00264    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 5120\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.744      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15309581 |\n",
      "|    clip_fraction        | 0.562      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.12       |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00595   |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00262    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 5632\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.73 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.733      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15212846 |\n",
      "|    clip_fraction        | 0.55       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.14       |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0123    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00255    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 6144\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.74 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.743      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15066132 |\n",
      "|    clip_fraction        | 0.553      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.15       |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0675    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 0.00248    |\n",
      "----------------------------------------\n",
      "Early stopping at step 8 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 6656\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.76 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.757      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 147        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15421851 |\n",
      "|    clip_fraction        | 0.6        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.15       |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0425    |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 0.00265    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 7168\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.752     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 149       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1620371 |\n",
      "|    clip_fraction        | 0.582     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.19      |\n",
      "|    explained_variance   | 0.943     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0194   |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -0.0247   |\n",
      "|    std                  | 0.18      |\n",
      "|    value_loss           | 0.00268   |\n",
      "---------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 7680\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.755      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15725133 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.28       |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0736    |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.00261    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 8192\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.766      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15120777 |\n",
      "|    clip_fraction        | 0.554      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.33       |\n",
      "|    explained_variance   | 0.933      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0635    |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.00258    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 8704\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.767      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15235443 |\n",
      "|    clip_fraction        | 0.578      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.37       |\n",
      "|    explained_variance   | 0.942      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0162    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.00263    |\n",
      "----------------------------------------\n",
      "Early stopping at step 8 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 9216\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.766      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15973455 |\n",
      "|    clip_fraction        | 0.599      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.36       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0307    |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0224    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 0.00272    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 9728\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.767      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17369819 |\n",
      "|    clip_fraction        | 0.561      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.4        |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00143   |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00382   |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00276    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 10240\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.77 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.77       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16757026 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.45       |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0562    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00276    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 10752\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.777      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15141554 |\n",
      "|    clip_fraction        | 0.571      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.44       |\n",
      "|    explained_variance   | 0.935      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0877     |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00676   |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 0.00281    |\n",
      "----------------------------------------\n",
      "Early stopping at step 6 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 11264\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.777     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1640095 |\n",
      "|    clip_fraction        | 0.596     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.47      |\n",
      "|    explained_variance   | 0.945     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0592   |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | -0.0192   |\n",
      "|    std                  | 0.178     |\n",
      "|    value_loss           | 0.0027    |\n",
      "---------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 11776\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.779      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17270389 |\n",
      "|    clip_fraction        | 0.581      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.55       |\n",
      "|    explained_variance   | 0.942      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0184    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00142   |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00272    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 12288\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.782     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 153       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1563157 |\n",
      "|    clip_fraction        | 0.56      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.6       |\n",
      "|    explained_variance   | 0.936     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.00551  |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -0.00199  |\n",
      "|    std                  | 0.177     |\n",
      "|    value_loss           | 0.0028    |\n",
      "---------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 12800\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.78       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17074156 |\n",
      "|    clip_fraction        | 0.571      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.64       |\n",
      "|    explained_variance   | 0.944      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00281    |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.00504   |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00271    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 13312\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.779      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16792402 |\n",
      "|    clip_fraction        | 0.571      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.69       |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0523     |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | 0.00282    |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00276    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 13824\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.78       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15331633 |\n",
      "|    clip_fraction        | 0.581      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.67       |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00402   |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | 0.00625    |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00268    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 14336\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.781     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1576331 |\n",
      "|    clip_fraction        | 0.573     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.65      |\n",
      "|    explained_variance   | 0.942     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.095     |\n",
      "|    n_updates            | 560       |\n",
      "|    policy_gradient_loss | 0.00828   |\n",
      "|    std                  | 0.177     |\n",
      "|    value_loss           | 0.00276   |\n",
      "---------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 14848\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.782      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16458245 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.63       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.01       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.00618   |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.00265    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 15360\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 5        |\n",
      "|    mean_reward          | 0.788    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 151      |\n",
      "|    iterations           | 1        |\n",
      "|    time_elapsed         | 16       |\n",
      "|    total_timesteps      | 2560     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.153929 |\n",
      "|    clip_fraction        | 0.577    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 6.66     |\n",
      "|    explained_variance   | 0.947    |\n",
      "|    learning_rate        | 0.0005   |\n",
      "|    loss                 | 0.0456   |\n",
      "|    n_updates            | 600      |\n",
      "|    policy_gradient_loss | 0.0082   |\n",
      "|    std                  | 0.177    |\n",
      "|    value_loss           | 0.00262  |\n",
      "--------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 15872\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.79       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17783757 |\n",
      "|    clip_fraction        | 0.584      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.71       |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.048      |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.000337  |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00256    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 16384\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.794      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15967788 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.74       |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0783     |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | 0.00979    |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00274    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 16896\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.79 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.794      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15356663 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.74       |\n",
      "|    explained_variance   | 0.948      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0115    |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | 0.00533    |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00252    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 17408\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.797      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15169568 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.76       |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0401     |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.00372   |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.0025     |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 17920\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.802      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15892448 |\n",
      "|    clip_fraction        | 0.582      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.77       |\n",
      "|    explained_variance   | 0.95       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0172     |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | 0.0109     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00238    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 18432\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.801      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15348962 |\n",
      "|    clip_fraction        | 0.553      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.77       |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0118     |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | 0.0152     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00254    |\n",
      "----------------------------------------\n",
      "Early stopping at step 5 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 18944\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.799      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15255633 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.77       |\n",
      "|    explained_variance   | 0.952      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0429     |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | 1.96e-05   |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00258    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 19456\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.802      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16221003 |\n",
      "|    clip_fraction        | 0.55       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.78       |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.149      |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | 0.0321     |\n",
      "|    std                  | 0.176      |\n",
      "|    value_loss           | 0.00262    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 19968\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.804      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15749474 |\n",
      "|    clip_fraction        | 0.575      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.8        |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0402     |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | 0.0189     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00244    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 20480\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.803      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15751919 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.83       |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00252    |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | 0.0296     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00258    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 20992\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.803      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 145        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15048592 |\n",
      "|    clip_fraction        | 0.565      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.83       |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0941     |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | 0.0185     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00253    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 21504\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.80 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.804      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15492173 |\n",
      "|    clip_fraction        | 0.584      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.85       |\n",
      "|    explained_variance   | 0.952      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0486     |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | 0.0191     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00259    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 22016\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.807      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16788858 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.9        |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0323     |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | 0.0386     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00234    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 22528\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.807      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15887555 |\n",
      "|    clip_fraction        | 0.571      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.92       |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.124      |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | 0.0262     |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.00265    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 23040\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.806      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17408888 |\n",
      "|    clip_fraction        | 0.581      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.95       |\n",
      "|    explained_variance   | 0.952      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.00162   |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | 0.017      |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00252    |\n",
      "----------------------------------------\n",
      "Early stopping at step 4 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 23552\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.81       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15487559 |\n",
      "|    clip_fraction        | 0.614      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.95       |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0292    |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | 0.00114    |\n",
      "|    std                  | 0.175      |\n",
      "|    value_loss           | 0.0025     |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 24064\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.81 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.814     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1509823 |\n",
      "|    clip_fraction        | 0.549     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 6.96      |\n",
      "|    explained_variance   | 0.952     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.0801    |\n",
      "|    n_updates            | 940       |\n",
      "|    policy_gradient_loss | 0.0417    |\n",
      "|    std                  | 0.174     |\n",
      "|    value_loss           | 0.00247   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 2 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 24576\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.818      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17568152 |\n",
      "|    clip_fraction        | 0.552      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.99       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0724     |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | 0.015      |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00257    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 25088\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.822      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15549724 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.03       |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0282     |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | 0.0323     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.0022     |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 25600\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.823     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1508818 |\n",
      "|    clip_fraction        | 0.586     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 7.05      |\n",
      "|    explained_variance   | 0.956     |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | 0.00314   |\n",
      "|    n_updates            | 1000      |\n",
      "|    policy_gradient_loss | 0.0249    |\n",
      "|    std                  | 0.174     |\n",
      "|    value_loss           | 0.0024    |\n",
      "---------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 26112\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.82 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.823      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16497877 |\n",
      "|    clip_fraction        | 0.597      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.08       |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0365     |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | 0.026      |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.00248    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 26624\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.826      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18358289 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.08       |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0382     |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | 0.0176     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00196    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 27136\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.828      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15214606 |\n",
      "|    clip_fraction        | 0.598      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.1        |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.075      |\n",
      "|    n_updates            | 1060       |\n",
      "|    policy_gradient_loss | 0.0232     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.00234    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 27648\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.827      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15502457 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.1        |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0174     |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | 0.0288     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00228    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.20\n",
      "\n",
      "Total episode rollouts: 28160\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.829      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20221226 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.09       |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0425     |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | 0.0235     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 0.00219    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 28672\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 148        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15106432 |\n",
      "|    clip_fraction        | 0.581      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.1        |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.014      |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | 0.0488     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.0022     |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.16\n",
      "\n",
      "Total episode rollouts: 29184\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15683493 |\n",
      "|    clip_fraction        | 0.589      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.15       |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0287    |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | 0.0248     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.00203    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 29696\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16935153 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.22       |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0283     |\n",
      "|    n_updates            | 1160       |\n",
      "|    policy_gradient_loss | 0.0253     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.00225    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 30208\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.831      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18228482 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.24       |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0601     |\n",
      "|    n_updates            | 1180       |\n",
      "|    policy_gradient_loss | 0.0457     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 0.00214    |\n",
      "----------------------------------------\n",
      "Early stopping at step 3 due to reaching max kl: 0.17\n",
      "\n",
      "Total episode rollouts: 30720\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.832      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17064345 |\n",
      "|    clip_fraction        | 0.618      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.25       |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0284    |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | 0.026      |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.00219    |\n",
      "----------------------------------------\n",
      "Early stopping at step 1 due to reaching max kl: 0.18\n",
      "\n",
      "Total episode rollouts: 31232\n",
      "\n",
      "Eval num_timesteps=2560, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.832      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18088919 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.29       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.135      |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | 0.0579     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 0.00235    |\n",
      "----------------------------------------\n",
      "Early stopping at step 2 due to reaching max kl: 0.15\n",
      "\n",
      "Total episode rollouts: 31744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-6af32b7e68ec>\", line 10, in <module>\n",
      "    seed=seed)\n",
      "  File \"/data/ad181/RemoteDir/ada_multigrid_ppo/utils/multigrid_framework_functions.py\", line 102, in multigrid_framework\n",
      "    model.learn(total_timesteps= env.terminal_step*episodes_per_iteration, callback=callback)\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\", line 264, in learn\n",
      "    reset_num_timesteps=reset_num_timesteps,\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 222, in learn\n",
      "    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 169, in collect_rollouts\n",
      "    if callback.on_step() is False:\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/stable_baselines3/common/callbacks.py\", line 88, in on_step\n",
      "    return self._on_step()\n",
      "  File \"/data/ad181/RemoteDir/ada_multigrid_ppo/utils/custom_eval_callback.py\", line 126, in _on_step\n",
      "    # Logs will be written in ``evaluations.npz``\n",
      "  File \"/data/ad181/RemoteDir/ada_multigrid_ppo/utils/custom_eval_callback.py\", line 28, in custom_evaluate_policy\n",
      "    env_ = deepcopy(env)\n",
      "  File \"/data/ad181/RemoteDir/ada_multigrid_ppo/utils/env_wrappers.py\", line 244, in step\n",
      "    state, reward, done, info = self.env.step(action)\n",
      "  File \"/data/ad181/RemoteDir/ada_multigrid_ppo/utils/env_wrappers.py\", line 181, in step\n",
      "    coarse_action = self.fine_to_coarse_action_mapping(action)\n",
      "  File \"/data/ad181/RemoteDir/ada_multigrid_ppo/utils/env_wrappers.py\", line 196, in fine_to_coarse_action_mapping\n",
      "    coarse_action_grid = fine_to_coarse_mapping(fine_action_grid, self.accmap, func=sum)\n",
      "  File \"/data/ad181/RemoteDir/ada_multigrid_ppo/utils/coarse_grid_functions.py\", line 130, in fine_to_coarse_mapping\n",
      "    return accum(accmap,fine_array, func)\n",
      "  File \"/data/ad181/RemoteDir/ada_multigrid_ppo/utils/coarse_grid_functions.py\", line 97, in accum\n",
      "    indx = tuple(accmap[s])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/ad181/anaconda3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for seed in range(1,4):\n",
    "    multigrid_framework(env_train, \n",
    "                        generate_model,\n",
    "                        generate_callback, \n",
    "                        delta_pcent=0.3, \n",
    "                        n=np.inf,\n",
    "                        grid_fidelity_factor_array =[1.0],\n",
    "                        episode_limit_array=[120000], \n",
    "                        log_dir=log_dir,\n",
    "                        seed=seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
